{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "kX6fJT3V4yV4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "RusCTEM71Sxd"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q3ef2hs4yV6",
        "outputId": "0920c447-6975-468d-e7e1-c43bd757d253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 10\n",
        "d_model = 512 #128\n",
        "\n",
        "num_heads = 8 #4\n",
        "num_layers = 6 #5\n",
        "dropout = 0.1 #0.3\n",
        "batch_size = 32 #\n",
        "len_seq = 6\n",
        "\n",
        "# 5000 permutacoes de 8 digitos\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "A0f76-Gz4yV7"
      },
      "outputs": [],
      "source": [
        "global ALREADY_PRINT\n",
        "ALREADY_PRINT = 0\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(self.vocab_size, self.d_model)\n",
        "        return self.embedding(x)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # implements the positional encoding function as the size of x\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        max_len = 512\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dk = d_model // num_heads\n",
        "\n",
        "        self.WO = nn.Linear(d_model, d_model)\n",
        "        self.WQ = nn.Linear(d_model, d_model)\n",
        "        self.WK = nn.Linear(d_model, d_model)\n",
        "        self.WV = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def attention(self, Q, K, V, dk, mask=False):\n",
        "        QKT = torch.matmul(Q, K.transpose(-2, -1))  # output dim: (batch_size, num_heads, n_tokens, n_tokens)\n",
        "        scaled_dot_product = torch.div(QKT, math.sqrt(dk))\n",
        "\n",
        "        if mask:\n",
        "            mask = torch.triu(torch.ones(QKT.size(-2), QKT.size(-1)), diagonal=1).bool().to(device)\n",
        "            scaled_dot_product = scaled_dot_product.masked_fill(mask, -float('inf'))\n",
        "            # print(\"Masked\")\n",
        "            # print(scaled_dot_product)\n",
        "            # ALREADY_PRINT = 1\n",
        "\n",
        "        sm = torch.nn.Softmax(dim=-1)\n",
        "        attention = sm(scaled_dot_product)\n",
        "        attention = self.dropout(attention)\n",
        "        return torch.matmul(attention, V)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=False):\n",
        "        Q = self.WQ(Q)\n",
        "        K = self.WK(K)\n",
        "        V = self.WV(V)\n",
        "\n",
        "        Q = Q.view(Q.size(0), -1, self.num_heads, self.dk).transpose(1, 2)  # Q: Why -1? A: It's a batch size\n",
        "        K = K.view(K.size(0), -1, self.num_heads, self.dk).transpose(1, 2)\n",
        "        V = V.view(V.size(0), -1, self.num_heads, self.dk).transpose(1, 2)\n",
        "\n",
        "        attention = self.attention(Q, K, V, self.dk, mask)\n",
        "        attention = attention.transpose(1, 2).contiguous().view(Q.size(0), -1, self.d_model)\n",
        "        return self.WO(attention)\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.multi_head_attention = MultiHeadAttention(d_model, num_heads, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_model, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = x + self.dropout1(self.multi_head_attention(x, x, x, mask))\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        x = x + self.dropout2(self.ff(x))\n",
        "        x = self.norm2(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, num_layers, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return x\n",
        "\n",
        "class MyTransformerDecoderOnly(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, num_layers,  dropout=0.1):\n",
        "        super(MyTransformerDecoderOnly, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, d_model)\n",
        "        self.transpose_embedding = nn.Linear(d_model, vocab_size)\n",
        "        self.transpose_embedding.weight = self.embedding.embedding.weight\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.decoder = Decoder(d_model, num_heads, num_layers, dropout)\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_enc(x)\n",
        "        x = self.decoder(x, mask)\n",
        "        x = self.linear(x)\n",
        "        # Transpos of emebedding\n",
        "        # x = self.transpose_embedding(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbR9p6vt4yWA"
      },
      "source": [
        "# Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "8MQ2IhLY4yWA"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "86_H0kof9XoH"
      },
      "outputs": [],
      "source": [
        "text = open('shakespeare.txt', 'r').read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "pHECJ2tDxWRh"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "class WordDataset(Dataset):\n",
        "    \"\"\"\n",
        "    arrange data and targets so that the first i elements of x\n",
        "    will be asked to predict the i-th element of y. Notice that\n",
        "    the eventual language model will actually make block_size\n",
        "    individual predictions at the same time based on this data,\n",
        "    so we are being clever and amortizing the cost of the forward\n",
        "    pass of the network. So for example if block_size is 4, then\n",
        "    we could e.g. sample a chunk of text \"w1 w2 w3 w4 w5\", the integers in\n",
        "    x will correspond to \"w1 w2 w3 w4\" and in y will be \"w2 w3 w4 w5\". This will\n",
        "    then actually \"multitask\" 4 separate examples at the same time\n",
        "    in the language model:\n",
        "    - given just \"w1\", please predict \"w2\" as next\n",
        "    - given \"w1 w2\" please predict \"w3\" next\n",
        "    - given \"w1 w2 w3\" predict \"w4\" next\n",
        "    - given \"w1 w2 w3 w4\" predict \"w5\" next\n",
        "    \"\"\"\n",
        "    def __init__(self, data, block_size):\n",
        "        words = re.split(r\"\\b\", data)\n",
        "        vocab = sorted(list(set(words)))\n",
        "        data_size, vocab_size = len(words), len(vocab)\n",
        "        print('data has %d words, %d unique.' % (data_size, vocab_size))\n",
        "\n",
        "        self.stoi = {word: i for i, word in enumerate(vocab)}\n",
        "        self.itos = {i: word for i, word in enumerate(vocab)}\n",
        "        self.block_size = block_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = words\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # grab a chunk of (block_size + 1) characters from the data\n",
        "        chunk = self.data[idx:idx + self.block_size + 1]\n",
        "        # encode every word to an integer\n",
        "        dix = [self.stoi[s] for s in chunk]\n",
        "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYf6vAwUxgW_",
        "outputId": "c49a10c4-a3db-4ab0-a268-0c8c73dc89f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 1980893 words, 34230 unique.\n"
          ]
        }
      ],
      "source": [
        "block_size = 128\n",
        "train_dataset = WordDataset(text, block_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly52q2FYxjm7",
        "outputId": "11cd3129-f653-403a-ca82-b28900073d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, shuffle=True, pin_memory=True, batch_size=batch_size\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "78ZA0xA54yWC"
      },
      "outputs": [],
      "source": [
        "num_layers = 2\n",
        "num_heads = 2\n",
        "d_model = 128\n",
        "vocab_size = train_dataset.vocab_size\n",
        "\n",
        "model = MyTransformerDecoderOnly(vocab_size,\n",
        "                                 d_model,\n",
        "                                 num_heads,\n",
        "                                 num_layers,\n",
        "                                 dropout).to(device).train()\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=6e-4)\n",
        "max_epochs = 1\n",
        "\n",
        "scheduler = lr_scheduler.PolynomialLR(optimizer, power=1, total_iters=max_epochs*len(train_dataset))\n",
        "\n",
        "\n",
        "# for epoch in range(max_epochs):\n",
        "#     pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "#     for it, (x, y) in pbar:\n",
        "#         x = x.to(device)\n",
        "#         y = y.to(device)\n",
        "# #         print(x.shape)\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         logits = model(x, True)\n",
        "#         loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "#         loss.backward()\n",
        "\n",
        "#         optimizer.step()\n",
        "#         # scheduler.step()\n",
        "\n",
        "#         pbar.set_description(f\"epoch {epoch} iter {it}: train loss {loss.item():.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "w0dOx4F67G6z"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "# # Save the model\n",
        "# torch.save({\n",
        "#     'model_state_dict': model.state_dict(),\n",
        "#     'optimizer_state_dict': optimizer.state_dict(),\n",
        "# }, 'model_checkpoint.pth')\n",
        "\n",
        "# # save the model\n",
        "# torch.save(model, 'model.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "wjUdIKxPEV3i"
      },
      "outputs": [],
      "source": [
        "# Delete the model\n",
        "# del model\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Load the model to CPU for inference\n",
        "model = MyTransformerDecoderOnly(vocab_size, d_model, num_heads, num_layers, dropout).to(device).eval()\n",
        "checkpoint = torch.load('model_checkpoint_jose.pth', map_location='cpu')\n",
        "model = torch.load('model_jose.pth')\n",
        "\n",
        "\n",
        "# Optional: Load optimizer state if needed\n",
        "optimizer = Adam(model.parameters(), lr=6e-4)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "LAzCx7kwXwka"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "block_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "q1uaDFb2wFGn"
      },
      "outputs": [],
      "source": [
        "def top_k_logits(logits, k):\n",
        "    v, ix = torch.topk(logits, k)\n",
        "    out = logits.clone()\n",
        "    out[out < v[:, [-1]]] = -float('Inf')\n",
        "    return out\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, x, steps, temperature=1.0, sample=False, top_k=None):\n",
        "    \"\"\"\n",
        "    take a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in\n",
        "    the sequence, feeding the predictions back into the model each time\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    for k in range(steps):\n",
        "        x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # crop context if needed\n",
        "        logits = model(x_cond, mask=True)\n",
        "        # pluck the logits at the final step and scale by temperature\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        # optionally crop probabilities to only the top k options\n",
        "        if top_k is not None:\n",
        "            logits = top_k_logits(logits, top_k)\n",
        "        # apply softmax to convert to probabilities\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        # sample from the distribution or take the most likely\n",
        "        if sample:\n",
        "            ix = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            _, ix = torch.topk(probs, k=1, dim=-1)\n",
        "        # append to the sequence and continue\n",
        "        x = torch.cat((x, ix), dim=1)\n",
        "\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO3SOMxywsqc",
        "outputId": "5c51b2a4-3a6e-4107-da25-67a37fc29870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O God, O God! \n",
            "      _Bosko\n",
            "      Varrius\n",
            "      solemnities!               draws\n",
            "      Varrius\n",
            "      entomb\n",
            "SON\n",
            "      inside\n",
            "      Varrius\n",
            "      entomb\n",
            "      golden\n",
            "      shade\n",
            "      Varrius\n",
            "      insufficience!\n",
            "               _Bosko\n",
            "      Varrius\n",
            "      insufficienceunpossessingprophetess\n",
            "      insufficience!\n",
            "               _Bosko\n",
            "inside\n",
            "      _Aside\n",
            "      maculation!\n",
            "               Varrius\n",
            "      insufficience!\n",
            "               _Bosko\n",
            "      Varrius\n",
            "      undistinguish\n",
            "      unchaste\n",
            "      frown\n",
            "      dragon\n",
            "      maledictions\n",
            "      Varrius\n",
            "      insufficience!\n",
            "\n",
            "           Stayest\n",
            "      golden\n",
            "      frown\n",
            "      forfeiters\n",
            "      specialties\n",
            "      snake\n",
            "      clocks\n",
            "Strong\n",
            "      golden\n",
            "      Varrius\n",
            "      fees\n",
            "      insufficience!\n",
            "               Varrius\n",
            "      faithfull\n",
            "LORDS\n",
            "      Varrius\n",
            "      solemnities\n",
            "      Varrius\n",
            "      insufficienceunpossessingprophetess\n",
            "      Varrius\n",
            "      fees\n",
            "      underborne!\n",
            "               _Bosko\n",
            "      Varrius\n",
            "      insufficience\n",
            "maledictions\n",
            "      snake\n",
            "      Gerland\n",
            "      maledictions\n",
            "      snake\n",
            "      quilt!\n",
            "\n",
            "           Roughly\n",
            "      Filth\n",
            "      unarmd\n",
            "      affied\n",
            "      lover\n",
            "      rifted\n",
            "      Varrius\n",
            "      throughout\n",
            "      sternage\n",
            "      envied\n",
            "      soit!\n",
            "\n",
            "           Lamentable\n",
            "      specialties\n",
            "      ista\n",
            "      affied\n",
            "      golden\n",
            "      Varrius\n",
            "      heroical!\n",
            "               smug\n",
            "      turvy\n",
            "      forfeited\n",
            "      treasons\n",
            "      Varrius\n",
            "      leathern\n",
            "      throughout\n",
            "throughout!\n",
            "               _Sweet\n",
            "      _Sweet\n",
            "      _Sweet\n",
            "      _Sweet\n",
            "      Varrius\n",
            "      insufficience\n",
            "      _Sweet\n",
            "      reconciled\n",
            "      hasten\n",
            "      rifted!\n",
            "               beautify\n",
            "      Varrius\n",
            "      insufficience\n",
            "      _Sweet\n",
            "      Filth\n",
            "      unfilial\n",
            "      lover\n",
            "lover\n",
            "      currance\n",
            "      lover\n",
            "      affied\n",
            "      hisse\n",
            "      specialties\n",
            "      likeliest\n",
            "      fees!           [Theirs\n",
            "      Belov!                 THRENOSSwornCrams\n",
            "      Muffle!                   Garlands!\n",
            "               Filth\n",
            "      unarmd\n",
            "      inside\n",
            "      hatefully\n",
            "      unchaste\n",
            "      unmask\n",
            "      Ego\n",
            "      _Bosko\n",
            "      Varrius\n",
            "      impregnable\n",
            "      fees\n",
            "underborneunpossessingprophetess\n",
            "      protractive\n",
            "      specialties\n",
            "      affied\n",
            "      feels!\n",
            "               _Bosko\n",
            "      snake\n",
            "      lodging\n",
            "      maledictions\n",
            "      sounded\n",
            "      forfeiters\n",
            "      hasten\n",
            "      snake\n",
            "insufficience\n",
            "      golden\n",
            "      frown\n",
            "      fluxive\n",
            "      _Bosko\n",
            "      smug\n",
            "      soldiership\n",
            "      unaware\n",
            "      lover\n",
            "      affied\n",
            "      lover\n",
            "      rifted\n",
            "      lessen\n",
            "      _Sweet\n",
            "      snake\n",
            "      filed\n",
            "      Warwick\n",
            "      maledictions\n",
            "      snake\n",
            "      undraws!\n",
            "\n",
            "           Lamentable\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      rooted\n",
            "      specialties\n",
            "      rudeness!\n",
            "\n",
            "           Rous\n",
            "      Gerland!\n",
            "               snake\n",
            "      sheav\n",
            "      maledictions\n",
            "      likeliest\n",
            "      fornication\n",
            "      fornication\n",
            "      Filth\n",
            "      foreshow\n",
            "      forgot.]\n",
            "948\n",
            "      snatchers\n",
            "      smug\n",
            "      Filth\n",
            "      unarmd\n",
            "      fare\n",
            "      soit\n",
            "      insufficience!                  Fitting\n",
            "      unluckily\n",
            "      affied\n",
            "      cygnets\n",
            "      Filth\n",
            "      currance\n",
            "      unluckily\n",
            "      lover\n",
            "      hips\n",
            "Dicky\n",
            "      likeliest\n",
            "      fornication\n",
            "      indulgent\n",
            "      specialties\n",
            "      soit\n",
            "      garden\n",
            "      envied\n",
            "      ista!—Stain\n",
            "      regions\n",
            "      Filth\n",
            "      foreshow\n",
            "Filth\n",
            "      societies\n",
            "      unluckily\n",
            "      maledictions\n",
            "      snake\n",
            "      Gerland!                   Garlands!                  Spur!\n",
            "               husks\n",
            "      ista\n",
            "      railer\n",
            "      ista\n",
            "      lover\n",
            "      Filth\n",
            "      foreshow\n",
            "      Varrius\n",
            "      undistinguish.—\n",
            "\n",
            "[Filth\n",
            "recanter\n",
            "      railer\n",
            "      affied\n",
            "      cygnets!—Fitting\n",
            "      hatefully\n",
            "      fliers\n",
            "      Varrius\n",
            "      insufficience\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      _Sweet\n",
            "      Filth\n",
            "      coppice\n",
            "      sleight\n",
            "      friskins\n",
            "Filth\n",
            "      hips\n",
            "      unmask\n",
            "      Ego\n",
            "      unarmd\n",
            "      affied\n",
            "      rifted\n",
            "      lessen\n",
            "      specialties\n",
            "      unmask\n",
            "      indigest\n",
            ";              \n",
            "      unluckily\n",
            "      _Puts\n",
            "      Varrius\n",
            "      fees\n",
            "      insufficience\n",
            "      maledictions\n",
            "      Varrius\n",
            "      hoistunpossessingprophetess\n",
            "      robb!—Filth\n",
            "      unfilial\n",
            "      dressings\n",
            "      pupil\n",
            "snake\n",
            "      irreconcil!\n",
            "               unluckily\n",
            "      _Puts\n",
            "      _Sweet\n",
            "      lessen\n",
            "      _Sweet\n",
            "      Varrius\n",
            "      insufficience\n",
            "      _Bosko\n",
            "      frown\n",
            "      leaver\n",
            "specialties\n",
            "      smokunpractisgardez!—Argier\n",
            "      Filth\n",
            "      unarmd\n",
            "      affied\n",
            "      lover\n",
            "      specialties\n",
            "      affied\n",
            "      hisse\n",
            "      specialties\n",
            "      affied\n",
            "      specialties\n",
            "      ista!\n",
            "\n",
            "           SON\n",
            "      fare\n",
            "      friskins\n",
            "      friskins\n",
            "      unchaste\n",
            "      shade\n",
            "      _Aside\n",
            "      _What\n",
            "      _Bosko\n",
            "      Varrius\n",
            "      insufficience\n",
            "      maledictions\n",
            "smug\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      lover!\n",
            "               _Bosko\n",
            "      Filthunpossessingimpudique\n",
            "      foreshow\n",
            "      likeliest\n",
            "      fornication!\n",
            "               beautify\n",
            "      snake\n",
            "      Gerlandunpossessingprophetess\n",
            "      complainer\n",
            "SON\n",
            "      affied\n",
            "      snake\n",
            "      Gerland\n",
            "      maledictions\n",
            "      snake\n",
            "      deifies!\n",
            "               _Sweet\n",
            "      snake\n",
            "      Gerland\n",
            "French\n",
            "      lover\n",
            "      smug\n",
            "      Varrius\n",
            "      insufficience\n",
            "      maledictions\n",
            "      unmask\n",
            "      mered\n",
            "      fornication\n",
            "      _Bosko\n",
            "      Varrius\n",
            "      faithfull!\n",
            "\n",
            "           948\n",
            "      forfeited\n",
            "      hasten\n",
            "      lover\n",
            "      Varrius\n",
            "      insufficience\n",
            "      _Bosko\n",
            "      Varrius\n",
            "      underborneunpossessingprophetess\n",
            "      indulgent.]\n",
            "Dicky\n",
            "      forfeited\n",
            "      hasten\n",
            "      Varrius\n",
            "      impregnable\n",
            "      maledictions\n",
            "      Varrius\n",
            "      throughout\n",
            "      impregnable\n",
            "      fees\n",
            "      durance.—\n",
            "\n",
            "[_Bosko\n",
            "      forfeited\n",
            "      foreigner\n",
            "      farer\n",
            "1164\n",
            "      insufficience\n",
            "      envied\n",
            "      soit!\n",
            "               _Bosko\n",
            "      snake\n",
            "      matches\n",
            "      undrawsunpossessingprophetess\n",
            "      limber!                  Filth\n",
            "      unarmd\n",
            "      Filth\n",
            "      societies\n",
            "      golden\n",
            "      indulgent\n",
            "      unluckily\n",
            "      foreshow\n",
            "      alacke!                   Mutes!                  Kate!\n",
            "               Filth\n",
            "      unarmd\n",
            "      fare\n",
            "      ista\n",
            "      Varrius\n",
            "      underborne!\n",
            "               Filth\n",
            "      hips\n",
            "      lover\n",
            "      tuae\n",
            "      unluckily\n",
            "      regions\n",
            "      affied\n",
            "Varrius\n",
            "      leathern\n",
            "      sternage\n",
            "      insufficience!\n",
            "               _Bosko\n",
            "      Filth\n",
            "      foreshow\n",
            "      forgot\n",
            "      ista\n",
            "      specialties\n",
            "      affied!           [Theirs!                 THRENOSSwornPEDANT\n",
            "      Finde!—Rous\n",
            "      provocations!—:\n",
            "\n",
            "             \n",
            "      misconst\n",
            "      maledictions\n",
            "      Varrius\n",
            "      insufficience\n",
            "      maledictions\n",
            "      snake\n",
            "      Gerland\n",
            "948\n",
            "      smug\n",
            "      turvy\n",
            "      Filth\n",
            "      regions\n",
            "      affied\n",
            "      cygnets.—\n",
            "\n",
            "[beautify\n",
            "      Filth\n",
            "      pupil\n",
            "Filth\n",
            "      currance\n",
            "      anchovies\n",
            "      friskins\n",
            "      unluckily\n",
            "      unarmd\n",
            "      affied\n",
            "      golden\n",
            "      snake\n",
            "      undraws!                  Filth\n",
            "      societies.—\n",
            "\n",
            "[giftes\n",
            "      snowballs\n",
            "      foreshow\n",
            "      Varrius\n",
            "      sobs\n",
            "      unluckily\n",
            "      foreshow\n",
            "      lover\n",
            "      Varrius\n",
            "underborneunpossessingprophetess\n",
            "      indulgent!—Rous\n",
            "      provocations\n",
            "      hasten\n",
            "      Varrius\n",
            "      insufficience!\n",
            "\n",
            "           Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      shoot\n",
            "      maledictions\n",
            "      snake\n",
            "      throughout\n",
            "      insufficience\n",
            "      hasten\n",
            "      specialties\n",
            "      unluckily!—Stain\n",
            "      _Puts\n",
            "      specialties\n",
            "      unmask\n",
            "      durance1069Swifter\n",
            "      foreshow\n",
            "      looks\n",
            "      lean\n",
            "      lean\n",
            "      maledictions\n",
            "      soit10Filthy!                  Sweats\n",
            "      maledictions\n",
            "      unmask\n",
            "      FRANCISCA!\n",
            "               likeliest\n",
            "      indexes!\n",
            "               reprisal!\n",
            "               beautify\n",
            "      Varrius\n",
            "      undistinguish\n",
            "      envied\n",
            "      snake\n",
            "throughout\n",
            "      fees\n",
            "      durance.—\n",
            "\n",
            "[turvy\n",
            "      hasten\n",
            "      Varrius\n",
            "      sobs\n",
            "      golden\n",
            "      Varrius\n",
            "      insufficience!\n",
            "\n",
            "           Filth\n",
            "      currance\n",
            "      lover\n",
            "      lover\n",
            "      railer\n",
            "      ista\n",
            "      specialties\n",
            "      snake\n",
            "      deux\n",
            "      maledictions\n",
            "      Varrius\n",
            "      companies!\n",
            "\n",
            "           ;              \n",
            "      unluckily\n",
            "      currance\n",
            "      specialties\n",
            "      unmask\n",
            "      indigest\n",
            "SON\n",
            "      inside\n",
            "      unluckily\n",
            "      Varrius\n",
            "      insufficience!\n",
            "               beautify\n",
            "      Varrius\n",
            "      insufficience\n",
            "      specialties\n",
            "      unmask\n",
            "      indigest\n",
            "948\n",
            "      unlicensed\n",
            "      affied\n",
            "      rifted\n",
            "      interchang\n",
            "      smug\n",
            "      turvy!\n",
            "               snake\n",
            "      fees\n",
            "      hoistunpossessingprophetess\n",
            "      fornication\n",
            "      Filth\n",
            "      unarmd!\n",
            "\n",
            "           Filth\n",
            "      foreshow\n",
            "      alacke\n",
            "      Varrius\n",
            "      insufficience\n",
            "      specialties\n",
            "      affied\n",
            "      specialties\n",
            "      unmask\n",
            "      durance!                   Crams\n",
            "      Inherit\n",
            "      Inherit\n",
            "      :\n",
            "\n",
            "\n",
            "      Ling\n",
            "      Murderer!\n",
            "               _Bosko\n",
            "      Varrius\n",
            "insufficience\n",
            "      maledictions\n",
            "      Varrius\n",
            "      faithfull\n",
            "      smug\n",
            "      Filthunpossessingimpudique\n",
            "      embroidery\n",
            "      snake\n",
            "      chirurgeonly\n",
            "      maledictions\n",
            "      unluckily!\n",
            "               turvy\n",
            "      Filth\n",
            "      regions\n",
            "      foreshow\n",
            "      specialties\n",
            "      unluckily\n",
            "      _Puts\n",
            "      Varrius\n",
            "      underborne\n",
            "LORDS\n",
            "      soit\n",
            "      beaten!\n",
            "               smug\n",
            "      Filth\n",
            "      unfilial\n",
            "      lover\n",
            "      affied\n",
            "      lover\n",
            "      golden\n",
            "      frown!\n",
            "               Filth\n",
            "      foreshow\n",
            "      alacke\n",
            "      unchaste\n",
            "Varrius\n",
            "      throughout\n",
            "      throughout\n",
            "      impregnable!—Filth\n",
            "      societies\n",
            "      Filth!\n",
            "               envied\n",
            "      Filth\n",
            "      beguiled\n",
            "      fare\n",
            "ista\n",
            "      hues\n",
            "      hatefully\n",
            "      hatefully\n",
            "      specialties\n",
            "      snake\n",
            "      deux\n",
            "      _Bosko\n",
            "      Filth\n",
            "      societies\n",
            "hatefully\n",
            "      hasten\n",
            "      Varrius\n",
            "      sobs\n",
            "      maledictions\n",
            "      hatefully!\n",
            "               loureth\n",
            "      Varrius\n",
            "      insufficience\n",
            "      Filth!\n",
            "               Filth\n",
            "      unarmd\n",
            "      fare\n",
            "      unluckily\n",
            "      lover\n",
            "      Varrius\n",
            "entomb!—Exceedingly\n",
            "      hasten\n",
            "      lover\n",
            "      specialties\n",
            "      Varrius\n",
            "      insufficience\n",
            "      golden\n",
            "      Varrius\n",
            "      underborne!\n",
            "               marrowless\n",
            "      Varrius\n",
            "      underborneunpossessingprophetess\n",
            "      gardez\n",
            "_Bosko\n",
            "      golden\n",
            "      frown\n",
            "      forfeiters\n",
            "      hasten\n",
            "      beautify\n",
            "      Varrius\n",
            "      insufficience\n",
            "      smug\n",
            "      treasons\n",
            "      forfeited\n",
            "      treasons\n",
            "specialties\n",
            "      foreshow\n",
            "      Filth\n",
            "      forgot\n",
            "      snaky!                   DON!                  Filth\n",
            "      unfilial\n",
            "      forfeited\n",
            "      affied\n",
            "      Varrius\n",
            "fees\n",
            "      insufficience1069948!\n",
            "               unluckily!\n",
            "               Filth\n",
            "      unfilial\n",
            "      unluckily\n",
            "      pupil\n",
            "      Varrius\n",
            "      sobs\n",
            "      maledictions\n",
            "      likeliest\n",
            "      fornication!\n",
            "               likeliest\n",
            "      indexes!\n",
            "\n",
            "           948\n",
            "      rifted\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      rooted\n",
            "      Filth!                   CRANMER!                  Stain\n",
            "      hasten\n",
            "      likeliest\n",
            "      indexes10Caesar_\n",
            "      Known\n",
            "      Consumption!                  Swifter\n",
            "      _Puts\n",
            "      lover!\n",
            "               Filth\n",
            "      unfilial\n",
            "      fare\n",
            "      unmask\n",
            "      fees\n",
            "      hoist\n",
            "      envied\n",
            "      hatefully!                  Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      rooted\n",
            "      lover.—\n",
            "\n",
            "[Filth\n",
            "      unfilial\n",
            "      currance\n",
            "      lover\n",
            "      hips!\n",
            "\n",
            "           Kent_\n",
            "      smug\n",
            "      Filth\n",
            "      fliers\n",
            "      alacke\n",
            "      likeliest\n",
            "      fornication\n",
            "      unarmd\n",
            "      affied\n",
            "      lover\n",
            "      golden\n",
            "      unmask\n",
            "Ego\n",
            "      hasten\n",
            "      beautify\n",
            "      golden\n",
            "      snake\n",
            "      undraws\n",
            "      maledictions\n",
            "      snake\n",
            "      sowl!\n",
            "               turvy\n",
            "      hasten\n",
            "      lover\n",
            "      rifted\n",
            "      lessen\n",
            "SON\n",
            "      railer\n",
            "      likeliest\n",
            "      rosunpossessingprophetess\n",
            "      imagine\n",
            "      specialties\n",
            "      railer\n",
            "      unluckily!                   NEIGHBOUR!                  Stain\n",
            "      hasten\n",
            "      soit\n",
            "      lolls\n",
            "      forfeited\n",
            "      bulls\n",
            "      envied\n",
            "      snake\n",
            "      undraws\n",
            "      unarmd\n",
            "      feasted\n",
            "SON\n",
            "      banks\n",
            "      hatefully\n",
            "      unchaste\n",
            "      unmask\n",
            "      FRANCISCA\n",
            "      _Bosko\n",
            "      Varrius\n",
            "      impregnable\n",
            "      example\n",
            "      hasten\n",
            "      snake\n",
            "      insufficience\n",
            "      maledictions\n",
            "      frown\n",
            "      mered\n",
            "spendthrift!\n",
            "               _Bosko\n",
            "      frown\n",
            "      forfeiters!\n",
            "               Varrius\n",
            "      throughout\n",
            "      unaccompaniedunpossessingprophetess\n",
            "      Varrius\n",
            "      underborne\n",
            "      golden\n",
            "      snake\n",
            "undraws\n",
            "      hasten\n",
            "      Varrius!               immure1069Filth\n",
            "      unfilial\n",
            "      lover\n",
            "      foreshow\n",
            "      Varrius\n",
            "      insufficience.—\n",
            "\n",
            "[_Bosko\n",
            "      Filth\n",
            "      currance\n",
            "      lover\n",
            "      hips!\n",
            "\n",
            "           Filth\n",
            "      foreshow\n",
            "      cygnets\n",
            "      specialties\n",
            "      affied\n",
            "      snake\n",
            "      clocks\n",
            "      maledictions\n",
            "      snake\n",
            "      hostage\n",
            "      hasten\n",
            "948\n",
            "      snake\n",
            "      undraws!\n",
            "               smug\n",
            "      hatefully\n",
            "      hasten\n",
            "      specialties\n",
            "      soit\n",
            "      companies\n",
            "      maledictions\n",
            "      frown\n",
            "      durance!                   Garlands\n",
            "      Mutes!                  Filth\n",
            "      foreshow\n",
            "      forgot\n",
            "      hatefully\n",
            "      specialties\n",
            "      affied\n",
            "      rifted\n",
            "      lessen\n",
            "      specialties\n",
            "      affied!                  Filthunpossessingimpudique\n",
            "      singularities\n",
            "      foul\n",
            "      likeliest\n",
            "      fornication\n",
            "      imagine\n",
            "      envied\n",
            "      snaky!—Knowes!\n",
            "               garter\n",
            "      soldiership\n",
            "      daintier\n",
            "      soldiership\n",
            "      currance!\n",
            "\n",
            "           SON\n",
            "      affied\n",
            "      lover\n",
            "      rifted\n",
            "      Filthunpossessingimpudique\n",
            "      fare\n",
            "      snaky\n",
            "      specialties\n",
            "      affied!                  Filth\n",
            "      foreshow\n",
            "      Varrius\n",
            "      insufficience\n",
            "      golden\n",
            "      snake\n",
            "      undraws\n",
            "      maledictions\n",
            "      likeliest\n",
            "      fees!\n",
            "               Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      shoot\n",
            "Roughly\n",
            "      smug\n",
            "      Filth\n",
            "      regions\n",
            "      foreshow\n",
            "      rak!                   Garlands\n",
            "      Lenten!                  Filth\n",
            "      unfilial\n",
            "      lover\n",
            "      fare\n",
            "      likeliest\n",
            "      invis\n",
            "      smug\n",
            "      Filth\n",
            "      foreshow\n",
            "      lover\n",
            "      specialties\n",
            "      likeliest\n",
            "      invis\n",
            "AUDREY\n",
            "      rifted\n",
            "      Filth\n",
            "      rifted\n",
            "      lessen\n",
            "      specialties\n",
            "      ista\n",
            "      Filth\n",
            "      foreshow\n",
            "      escapt\n",
            "      likeliest\n",
            "      fornication\n",
            "948\n",
            "      smug\n",
            "      soldiership\n",
            "      commenc\n",
            "      daintier\n",
            "      Filth\n",
            "      indulgent\n",
            "      ista\n",
            "      specialties\n",
            "      snaky!                   Mutes!                  Spur!\n",
            "               likeliest\n",
            "      indexes1069Stocking\n",
            "      hasten\n",
            "      smug\n",
            "      Filth\n",
            "      unarmd\n",
            "      lover\n",
            "      affied\n",
            "      rifted\n",
            "      lessen!—Fitting\n",
            "      Filth\n",
            "      foreshow\n",
            "      lover\n",
            "      alacke\n",
            "      golden\n",
            "likeliest\n",
            "      gentlerunpossessingprophetess\n",
            "      fornication!\n",
            "\n",
            "           Filthunpossessingimpudique\n",
            "      embroidery\n",
            "      snake\n",
            "      sowl\n",
            "      specialties\n",
            "      frown\n",
            "      drawne!\n",
            "\n",
            "           948\n",
            "      Filth\n",
            "      recanter\n",
            "      embroidery\n",
            "      friskins!—Filth\n",
            "      unarmd\n",
            "      lover\n",
            "      feasted\n",
            "      specialties\n",
            "      unluckily!\n",
            "\n",
            "           948\n",
            "      husks\n",
            "      ista\n",
            "      railer\n",
            "      ista\n",
            "      specialties\n",
            "      rudeness\n",
            "      likeliest\n",
            "      imagine!                  Filth\n",
            "      unarmd\n",
            "      lover\n",
            "      feasted\n",
            "      specialties\n",
            "      railer\n",
            "      snaky!\n",
            "               Filth\n",
            "      currance\n",
            "      anchovies\n",
            "      unluckily.—\n",
            "\n",
            "[likeliest\n",
            "      indexes!                   DON!                  Stocking!\n",
            "               reprisal!\n",
            "               likeliest\n",
            "      indexes10Caesars!-Tailor': Stain\n",
            "      hasten\n",
            "      snake\n",
            "      throughout\n",
            "      indexes!\n",
            "               likeliest\n",
            "      indexes\n",
            "’Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      Filthunpossessingimpudique\n",
            "      affied\n",
            "      lover\n",
            "      lover\n",
            "      Varrius\n",
            "      underborne\n",
            "      maledictions\n",
            "      snake\n",
            "insufficience\n",
            "      maledictions\n",
            "      snake\n",
            "      irreconcil!\n",
            "               _Bosko\n",
            "      golden\n",
            "      unmask\n",
            "      fees\n",
            "      durance!—Filth\n",
            "      hips\n",
            "      unluckily\n",
            "      lover\n",
            "      lover\n",
            "      lover\n",
            "      garter\n",
            "      Filth\n",
            "      coppice!—Filth\n",
            "      foreshow\n",
            "      looks\n",
            "insufficience!\n",
            "               Filth\n",
            "      unarmd\n",
            "      fare\n",
            "      friskins\n",
            "      golden\n",
            "      likeliest\n",
            "      fluxive\n",
            "      smug\n",
            "      Filth\n",
            "      unarmd\n",
            "      lover\n",
            "      societies\n",
            "      specialties\n",
            "      snaky!           [Theirs\n",
            "      Phoenicia!                 THRENOSSwornPEDANT\n",
            "      Finde!—1164\n",
            "      negotiations!—1164\n",
            "      Orphans\n",
            "      maledictions\n",
            "      snake\n",
            "      Live!                                      [Crams\n",
            "      unchaste\n",
            "      snake\n",
            "      Broach!                   DREAM\n",
            "      Goffe!                  1164\n",
            "      privacy\n",
            "      specialties\n",
            "      unmask\n",
            "      commonwealth!\n",
            "               Filth\n",
            "      currance\n",
            "      anchovies\n",
            "      friskins!—Swifter\n",
            "      foreshow\n",
            "      alacke\n",
            "      unchaste\n",
            "      Varrius\n",
            "      insufficienceunpossessingprophetess\n",
            "      commonwealth\n",
            "948\n",
            "      Filth\n",
            "      unfilial\n",
            "      foreshow\n",
            "      unluckily\n",
            "      Varrius\n",
            "      leathern\n",
            "      insufficience1069Kate\n",
            "      lean\n",
            "      smoke\n",
            "      unluckily\n",
            "      foreshow\n",
            "      rak\n",
            "Roses\n",
            "      specialties\n",
            "      unluckily\n",
            "      regions\n",
            "      Filth\n",
            "      foreshow\n",
            "      forgot\n",
            "      friskins\n",
            "      unchaste\n",
            "      snaky!                  Rous\n",
            "      loopholes\n",
            "      indexes\n",
            "      recanter\n",
            "      affied\n",
            "      hisse!—Fitting\n",
            "      forfeited\n",
            "      trusted\n",
            "      lover\n",
            "      specialties\n",
            "      unmask\n",
            "      Ego!                  Swifter\n",
            "      islands\n",
            "      lover\n",
            "      affied\n",
            "      snake\n",
            "      insufficience\n",
            "      maledictions\n",
            "      likeliest\n",
            "      imagine!                  Filth\n",
            "      unarmd\n",
            "      lover\n",
            "      foreshow\n",
            "      Filth\n",
            "      forgot\n",
            "      likeliest\n",
            "      durance\n",
            "      maledictions\n",
            "      indulgent!\n",
            "\n",
            "           Dicky\n",
            "      hatefully\n",
            "      hasten\n",
            "      beautify\n",
            "      Varrius\n",
            "      throughout\n",
            "      sternage.—\n",
            "\n",
            "[beautify\n",
            "      Filth\n",
            "]\n",
            "\n",
            "[\n",
            "      Varrius\n",
            "      entomb\n",
            "      specialties\n",
            "      friskins\n",
            "      _Sweet\n",
            "      hatefully\n",
            "      Filth\n",
            "      beguiled\n",
            "      societies!                  Fitting\n",
            "      unluckily\n",
            "      trusted\n",
            "      Varrius\n",
            "      entomb!—Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      Filth\n",
            "      unfilial\n",
            "      lover\n",
            "      foreshow\n",
            "      unluckily\n",
            "      golden\n",
            "      snake\n",
            "undraws.—\n",
            "\n",
            "[turvy\n",
            "      unluckily\n",
            "      lieutenant\n",
            "      livers\n",
            "      affied\n",
            "      rifted\n",
            "      lessen\n",
            "      specialties\n",
            "      likeliest\n",
            "      fees\n",
            "      fees\n",
            "      durance\n",
            "      maledictions\n",
            "snake\n",
            "      chirurgeonly!—Fitting\n",
            "      unluckily\n",
            "      currance!\n",
            "               affied\n",
            "      Varrius\n",
            "      underborne!—Filthunpractisdriving!\n",
            "               Filthunpossessingimpudique\n",
            "      lover\n",
            "      rudeness!\n",
            "               envied\n",
            "      hatefully\n",
            "      trusted\n",
            "      Varrius\n",
            "      insufficience!\n",
            "               _Sweet\n",
            "illumineth\n",
            "      _Sweet\n",
            "      forfeited\n",
            "      trusted\n",
            "      specialties\n",
            "      affied\n",
            "      feels!\n",
            "               _Bosko\n",
            "      unluckily\n",
            "      specialties\n",
            "      snake\n",
            "      undraws\n",
            "maledictions\n",
            "      likeliest\n",
            "      fornication\n",
            "      unaccompanied\n",
            "      maledictions\n",
            "      snake\n",
            "      lolls\n",
            "      maledictions\n",
            "      snake\n",
            "      undrawsunpossessingprophetess\n",
            "      imagine\n",
            "948\n",
            "      snake\n",
            "      undraws!—Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      Varrius\n",
            "      faithfull!                   Dainties!                  Stocking!\n",
            "               tuae\n",
            "      hasten\n",
            "      forfeited\n",
            "      hasten\n",
            "      Varrius\n",
            "      insufficience1069French\n",
            "      snake\n",
            "      irreconcil\n",
            "LORDS\n",
            "      snake\n",
            "      fees\n",
            "      lolls!\n",
            "               Varrius\n",
            "      impregnable\n",
            "      insufficienceunpossessingprophetess\n",
            "      unaccompanied10Lift!                  Filth\n",
            "      unarmd\n",
            "      affied\n",
            "      lover.—\n",
            "\n",
            "[envied\n",
            "      Filthunpossessingimpudique\n",
            "      affied\n",
            "      lover\n",
            "      specialties\n",
            "      affied!                   154\n",
            "      Known\n",
            "      Consumption!                  Argier\n",
            "      unluckily\n",
            "      specialties\n",
            "      affied\n",
            "      likeliest\n",
            "      barnes!                   DON!                  Stain\n",
            "      hasten\n",
            "      snake\n",
            "      irreconcil10Assail!                  ?\n",
            "    '!\n",
            "               smug\n",
            "      hasten\n",
            "      snake\n",
            "      irreconcil\n",
            "      maledictions\n",
            "      snake\n",
            "      undraws\n",
            "      maledictions\n",
            "      likeliest\n",
            "      barnes!\n",
            "\n",
            "           Stayest\n",
            "      treasons\n",
            "      snake\n",
            "      undraws\n",
            "      specialties\n",
            "      snake\n",
            "      deux!\n",
            "               _Bosko\n",
            "      forfeited\n",
            "      unarmd\n",
            "      inside\n",
            "      Varrius\n",
            "      sobs\n",
            "SON\n",
            "      railer\n",
            "      likeliest\n",
            "      durance\n",
            "      _Bosko\n",
            "      Varrius\n",
            "      hoist!\n",
            "               smug\n",
            "      hasten\n",
            "      Varrius\n",
            "      throughout\n",
            "      heroical!\n",
            "\n",
            "           Filth\n",
            "      unfilial\n",
            "      lover\n",
            "      affied\n",
            "      _Sweet\n",
            "      trumpet_!               dyer\n",
            "      golden\n",
            "      indulgent!\n",
            "               _Bosko\n",
            "      smug\n",
            "      hasten\n",
            "Rous\n",
            "      leathern\n",
            "      throughout\n",
            "      sternage!—Stain\n",
            "      hasten\n",
            "      hatefully\n",
            "      snake\n",
            "      Gerland\n",
            "      treasons\n",
            "      snake\n",
            "      undraws!                  Rous\n",
            "      provocations\n",
            "      provocations\n",
            "      hasten\n",
            "      Varrius\n",
            "      leathern\n",
            "      heroical!\n",
            "               Varrius\n",
            "      insufficience!                   Garlands\n",
            "      Conspirators!                  Stain\n",
            "      treasons\n",
            "      soit101634!                  Exceedingly\n",
            "      hasten\n",
            "      snake\n",
            "      throughout\n",
            "      orthography\n",
            "      concord.—\n",
            "\n",
            "[_Bosko\n",
            "      smug\n",
            "      Filth\n",
            "      fliersunpossessingsimpleness!                  Filth\n",
            "      unfilial\n",
            "      inside\n",
            "      likeliest\n",
            "      duranceunpossessingcollusion\n",
            "      specialties\n",
            "      snake\n",
            "      Gerland\n",
            "      foreigner\n",
            "SON\n",
            "      affied\n",
            "      Varrius\n",
            "      hereditary!               attentive\n",
            "      smug\n",
            "      provocations\n",
            "      maledictions\n",
            "      hatefully1069Kate\n",
            "      hasten\n",
            "      likeliest\n",
            "      fees\n",
            "      invisunpossessingprophetess\n",
            "      Varrius\n",
            "      impregnable\n",
            "      insufficience!\n",
            "               Filth\n",
            "      regions\n",
            "foreshow\n",
            "      Varrius\n",
            "      undistinguish\n",
            "      envied\n",
            "      Varrius\n",
            "      underborneunpossessingprophetess\n",
            "      protractive!                   Crams\n",
            "      Inherit\n",
            "      Ling!                   Lift\n",
            "      _Bosko\n",
            "      snake\n",
            "      hymn!                   Mutes!                  Iwis\n",
            "      indexes!\n",
            "               Filth\n",
            "      currance\n",
            "      _kills\n",
            "      likeliest\n",
            "      indexes!\n",
            "               Filth\n",
            "      currance\n",
            "      lover\n",
            "      rudeness.]\n",
            "Rous\n",
            "      feebleness!\n",
            "               _Bosko\n",
            "      golden\n",
            "      snake\n",
            "      undraws\n",
            "      maledictions\n",
            "      soit\n",
            "      undraws!\n",
            "\n",
            "           Argier\n",
            "      snake\n",
            "      undraws\n",
            "      smug\n",
            "      hasten\n",
            "      lover\n",
            "      snake\n",
            "      sowl\n",
            "      maledictions\n",
            "      matrons\n",
            "      forted!                  Rous\n",
            "      undraws\n",
            "      _Puts\n",
            "      lover\n",
            "      snake\n",
            "      animis\n",
            "      maledictions\n",
            "      likeliest\n",
            "      fees\n",
            "      indexes!                   Mousetrap\n",
            "      Hereditary!                  Knowes\n",
            "      smug\n",
            "      Filth\n",
            "      unarmd\n",
            "      fare\n",
            "      unluckily\n",
            "      looks\n",
            "      lean.]\n",
            "Filth\n",
            "      unarmd\n",
            "      lover\n",
            "      sleight!\n",
            "               _Bosko\n",
            "      rifted\n",
            "      lessen\n",
            "      hatefully\n",
            "SON\n",
            "      singularities\n",
            "      hatefully\n",
            "      unchaste\n",
            "      shade\n",
            "      _Sweet\n",
            "      snake\n",
            "      Gerland\n",
            "      _Bosko!—Filth\n",
            "      unarmd\n",
            "      currance\n",
            "      lover\n",
            "      rudeness!                   Mousetrap!                  Stain\n",
            "      treasons\n",
            "      hatefully\n",
            "      lover\n",
            "      likeliest\n",
            "      durance!                   ?’\n",
            "\n",
            "!                  Knowes!\n",
            "               reprisal!\n",
            "               snatchers!\n",
            "               reprisal!\n",
            "\n",
            "           Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      shoot!\n",
            "               Filth\n",
            "      unarmd\n",
            "      affied\n",
            "      lover\n",
            "      beautify\n",
            "      specialties\n",
            "      railer\n",
            "      snaky\n",
            "      smug\n",
            "      Filthunpossessingimpudique\n",
            "      lover!                   Assail!                  Stain\n",
            "      hasten\n",
            "      unmask\n",
            "      unelected\n",
            "      spet1069Filth\n",
            "      unfilial\n",
            "      lover\n",
            "      hips\n",
            "      ista\n",
            "      lover\n",
            "      tuae\n",
            "      Filth!\n",
            "\n",
            "           Argier\n",
            "      foreshow\n",
            "      Varrius\n",
            "      insufficience\n",
            "      hasten\n",
            "      Varrius\n",
            "      insufficience!—Exceedingly\n",
            "      unarmd\n",
            "      affied\n",
            "      Varrius\n",
            "      insufficience\n",
            "      envied\n",
            "      likeliest\n",
            "commonwealth!—Knowes!\n",
            "               smug\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      Filth\n",
            "      lover\n",
            "      Varrius\n",
            "      underborneunpossessingprophetess\n",
            "      indulgent!\n",
            "\n",
            "           Roughly\n",
            "      Filth\n",
            "      unarmd\n",
            "      affied\n",
            "      rifted\n",
            "      specialties\n",
            "      ista!—Stain\n",
            "      hasten\n",
            "      snake\n",
            "      undraws\n",
            "      hasten\n",
            "      smug\n",
            "      reconciled\n",
            "      unarmd\n",
            "      affied\n",
            "      goldenunpossessingdriving\n",
            "      specialties\n",
            "      ista!                   Garlands\n",
            "      Mutes!                  Spur!\n",
            "               unluckily\n",
            "      unfilial!\n",
            "               Filth\n",
            "      foreshow\n",
            "      cygnets\n",
            "      specialties\n",
            "      likeliest\n",
            "      indexes!\n",
            "\n",
            "           Roughlyunpossessingprophetess\n",
            "      Varrius\n",
            "      undistinguish\n",
            "      trusted\n",
            "      Varrius\n",
            "      impregnable\n",
            "      heroical\n",
            "Roughly\n",
            "      hasten\n",
            "      Varrius\n",
            "      insufficience\n",
            "      _Bosko\n",
            "      smug\n",
            "      forfeited\n",
            "      treasons\n",
            "      snake\n",
            "      throughout\n",
            "      leathern\n",
            "      loopholes\n",
            "      example\n",
            "      _Bosko\n",
            "      snake\n",
            "twold\n",
            "      undraws\n",
            "      hasten\n",
            "      snake\n",
            "      sowl\n",
            "SON\n",
            "      affied\n",
            "      _Sweet\n",
            "      forfeited\n",
            "      hasten\n",
            "      Varrius\n",
            "      impregnable!                   Garlands!                  Iwis\n",
            "      illusions!\n",
            "               likeliest\n",
            "      indigent!                   Mutes!-Taffeta\n",
            "      _Bosko\n",
            "      Enforce!                 THRENOSTARQUINIUSKnowes!\n",
            "               tuae\n",
            "      hasten\n",
            "      likeliest\n",
            "      indexes\n",
            "      _Puts\n",
            "      Varrius\n",
            "      faithfull\n",
            "948\n",
            "      Filth\n",
            "      foreshow\n",
            "      inhooped\n",
            "      likeliest\n",
            "      indexes!—Exceedingly\n",
            "      foreigner\n",
            "      Varrius\n",
            "      insufficience\n",
            "      envied\n",
            "Varrius\n",
            "      throughout\n",
            "      insufficience\n",
            "      hasten\n",
            "      Varrius\n",
            "      insufficience\n",
            "      envied\n",
            "      friskins!\n",
            "               smug\n",
            "      forfeited\n",
            "      fliers\n",
            "      alacke!                   Assail!                  Argier\n",
            "      reconciled\n",
            "      unfilial\n",
            "      reconciled!\n",
            "               giftes\n",
            "      reconciled\n",
            "      affied\n",
            "      protection\n",
            "      franchises\n",
            "      specialties\n",
            "      franchises!\n",
            "\n",
            "           948\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      Filth\n",
            "      coppice\n",
            "      fare\n",
            "      likeliest\n",
            "      gentler!—Fitting\n",
            "      Filth\n",
            "      foreshow!\n",
            "\n",
            "           Filth\n",
            "      fliers\n",
            "      alacke\n",
            "      Varrius\n",
            "      underborne\n",
            "      maledictions\n",
            "      indulgent!\n",
            "\n",
            "           948\n",
            "      Filth\n",
            "      foreshow\n",
            "      Varrius\n",
            "      impregnable\n",
            "      insufficienceunpossessingprophetess\n",
            "      fluxive.—\n",
            "\n",
            "[_Bosko\n",
            "      Filth\n",
            "      foreshow\n",
            "      alacke\n",
            "      specialties\n",
            "      snaky!\n",
            "\n",
            "           ;              !\n",
            "               specialties\n",
            "      snake\n",
            "      undraws!\n",
            "               Filth\n",
            "      beholdest\n",
            "      affied\n",
            "      rifted\n",
            "      lessen\n",
            "      Varrius\n",
            "      underborne\n",
            "SON\n",
            "      inside\n",
            "      snake\n",
            "      undraws\n",
            "      golden\n",
            "      sounded\n",
            "      fluxive\n",
            "      Filth\n",
            "      currance\n",
            "      societies\n",
            "      soldiership\n",
            "commencunpossessingsarcenet\n",
            "      soldiership\n",
            "      sounded\n",
            "      limber!—SATURNINUS\n",
            "      _Squeezes\n",
            "      soldiership\n",
            "      lover\n",
            "      _Squeezes!                   Assail!                  Stocking!\n",
            "               Filthunpossessingimpudique\n",
            "      lover\n",
            "      pupil\n",
            "      soldiership\n",
            "      forceful\n",
            "      soldiership\n",
            "      sounded\n",
            "      forfeiters!\n",
            "\n",
            "           Lamentable\n",
            "      sounded\n",
            "      indulgent\n",
            "      maledictions\n",
            "      sobriety\n",
            "      drank!\n",
            "               Filth\n",
            "      foreshow\n",
            "      rak\n",
            "      snaky\n",
            "Flowres\n",
            "      Varrius\n",
            "      heroical\n",
            "      maledictions\n",
            "      sounded\n",
            "      indulgent!\n",
            "               likeliest\n",
            "      indulgent!\n",
            "\n",
            "           948\n",
            "      sounded\n",
            "      indulgent\n",
            "      sounded\n",
            "      indulgent\n",
            "      Filth\n",
            "      lover\n",
            "      snaky!\n",
            "               loureth\n",
            "      soldiership\n",
            "commencunpossessingsarcenet\n",
            "      soldiership\n",
            "      lover\n",
            "      Varrius\n",
            "      insufficience\n",
            "      maledictions\n",
            "      snake\n",
            "      undraws!                   Gloucestershire!                  948\n",
            "      Filth\n",
            "      societies\n",
            "      soldiership\n",
            "      lover\n",
            "      rudeness\n",
            "      lover\n",
            "      sounded\n",
            "      leaverunpossessingprophetess\n",
            "      imagine!\n",
            "\n",
            "           SATURNINUS\n",
            "      forceful\n",
            "      Varrius\n",
            "      sprited\n",
            "      specialties\n",
            "      affied\n",
            "      rifted\n",
            "      Varrius\n",
            "      sprited!—948\n",
            "      sounded\n",
            "      fornication!\n",
            "\n",
            "           SATURNINUS!\n",
            "               daintier\n",
            "      soldiership!\n",
            "               smug\n",
            "      soldiership\n",
            "      unaware\n",
            "      lover\n",
            "      affied\n",
            "      sounded\n",
            "      silenc.]\n",
            "Argier\n",
            "      Filth\n",
            "      unfilial\n",
            "      Filth\n",
            "      foreshow\n",
            "      cygnets\n",
            "      snaky\n",
            "      lover\n",
            "      Varrius\n",
            "      fees\n",
            "      fornication!                   Mousetrap!                  Stocking\n",
            "      snatchers\n",
            "      soldiership\n",
            "      daintier\n",
            "      affied\n",
            "      likeliest\n",
            "      fornication!                   Garland!                  Spur!\n",
            "               Filth\n",
            "      hips\n",
            "      lover!\n",
            "               _Bosko\n",
            "      rifted!                  Filth\n",
            "      recanter\n",
            "      embroidery!\n",
            "               envied\n",
            "      sounded\n",
            "      indulgent!\n",
            "               specialties\n",
            "      soit\n",
            "      sowl!\n",
            "\n",
            "           Roughlyunpossessingprophetess\n",
            "      snake\n",
            "      animis\n",
            "      maledictions\n",
            "      soit\n",
            "      undraws\n",
            "      hasten\n",
            "      Varrius\n",
            "      fees!\n",
            "\n",
            "           948\n",
            "      smug\n",
            "      soldiership\n",
            "      received\n",
            "      affied\n",
            "      lover\n",
            "      lover!\n",
            "               Filth\n",
            "      foreshow\n",
            "      likeliest\n",
            "      fornication!\n",
            "               marrowless\n",
            "      Filth!                  Stain\n",
            "      currance\n",
            "      hatefully\n",
            "      snatchers\n",
            "      Filth\n",
            "      anchovies\n",
            "      unluckily\n",
            "      foreshow\n",
            "      lover\n",
            "      lover\n",
            "      tuae\n",
            "      Filth\n",
            "      beguiled\n",
            "      lover\n",
            "      foreshow\n",
            "      rak\n",
            "      ista!                  Argier\n",
            "      Filth\n",
            "      unarmd\n",
            "      lover\n",
            "      currance\n",
            "      unluckily\n",
            "      hips!\n",
            "               likeliest\n",
            "      indexes!           [Theirs!                 THRENOSSwornGarlands\n",
            "      Enrings!                  Iwis\n",
            "      indexes\n",
            "                                                Mutes!                  948\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      aught\n",
            "      maledictions\n",
            "      likeliest\n",
            "      barnes!\n",
            "\n",
            "           948\n",
            "      smug\n",
            "      Filth\n",
            "      beguiled\n",
            "      lover\n",
            "      sleight\n",
            "      snaky!\n",
            "               _Sweet\n",
            "      soldiership\n",
            "      forceful\n",
            "      hatefully!—SATURNINUS\n",
            "flieth\n",
            "      soldiership\n",
            "      forceful\n",
            "      Varrius\n",
            "      sobs!—Filth\n",
            "      foreshow\n",
            "      looks\n",
            "      irreconcil!\n",
            "\n",
            "           948\n",
            "      golden\n",
            "      frown\n",
            "      fluxive\n",
            "      specialties\n",
            "      likeliest\n",
            "      fornication\n",
            "      fornication!                   Garlands!                  Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      lover\n",
            "      Varrius\n",
            "      insufficience\n",
            "      maledictions\n",
            "      indulgent\n",
            "      maledictions\n",
            "      frown\n",
            "      durance!—Filth\n",
            "      unarmd\n",
            "      affied\n",
            "      lover\n",
            "      smug\n",
            "Stayest\n",
            "      unfilial\n",
            "      affied\n",
            "      rifted!—Filth\n",
            "      foreshow\n",
            "      rak\n",
            "      Varrius\n",
            "      insufficience\n",
            "      hasten\n",
            "      snake\n",
            "      entomb.]\n",
            "Rous\n",
            "      throughout\n",
            "      fees\n",
            "      insufficience\n",
            "      smug\n",
            "      soldiership\n",
            "      copulation\n",
            "      affied\n",
            "      Varrius\n",
            "      server\n",
            "      specialties\n",
            "      snake\n",
            "      Gerlandunpossessingprophetess\n",
            "      limber\n",
            "      maledictions\n",
            "      snake\n",
            "      insufficience\n",
            "      foreigner\n",
            "      alacke\n",
            "SON\n",
            "      inside\n",
            "      Varrius!               attentive\n",
            "      specialties\n",
            "      ista\n",
            "      affied\n",
            "      specialties\n",
            "      affied\n",
            "      feels!                  Rous\n",
            "      insufficience\n",
            "      maledictions\n",
            "      frown\n",
            "      fyres\n",
            "      unarmd\n",
            "      lover\n",
            "      affied\n",
            "      cygnets\n",
            "      golden\n",
            "snake\n",
            "      undraws\n",
            "      _Bosko\n",
            "      forfeited\n",
            "      foreigner\n",
            "      farer\n",
            "      frown\n",
            "      mered.—\n",
            "\n",
            "[marrowless\n",
            "      depths!\n",
            "               _Bosko\n",
            "      forfeited\n",
            "      treasons\n",
            "      lover\n",
            "      Varrius\n",
            "      heroical\n",
            "      envied\n",
            "      likeliest\n",
            "      durance\n",
            ";              \n",
            "      giftes\n",
            "      forfeited\n",
            "      unfilial\n",
            "      inside\n",
            "      snarl\n",
            "      golden\n",
            "      likeliest\n",
            "      durance!—Argier\n",
            "      forfeited\n",
            "      foreigner\n",
            "      cygnets\n",
            "1164\n",
            "      solemnities\n",
            "      _Sweet\n",
            "      Varrius\n",
            "      insufficience\n",
            "      Filth\n",
            "      unfilial\n",
            "      lover\n",
            "      affied\n",
            "      lover\n",
            "      specialties\n",
            "      affied\n",
            "      specialties\n",
            "      frown\n",
            "      limber.]\n",
            "948\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      aught!\n",
            "               _Bosko\n",
            "      forfeitedunpossessingprophetess\n",
            "      looks\n",
            "      lean\n",
            "      hurts!\n",
            "\n",
            "           948\n",
            "      rifted\n",
            "      duchy\n",
            "      _Sweet\n",
            "      soldiership\n",
            "      unaware\n",
            "      rudeness\n",
            "      specialties\n",
            "      sounded\n",
            "      durance\n",
            ";              \n",
            "      _Sweet\n",
            "      Filth\n",
            "      unarmd\n",
            "      foreshow\n",
            "      lover\n",
            "      rak\n",
            "      specialties\n",
            "      affied\n",
            "948\n",
            "      rifted\n",
            "      filed\n",
            "      maledictions\n",
            "      likeliest\n",
            "      imagineunpossessingprophetess\n",
            "      indulgent\n",
            "      specialties\n",
            "      friskins\n",
            "      golden\n",
            "      unmask\n",
            "      indigest!—Fitting\n",
            "forfeited\n",
            "      trusted\n",
            "      lover\n",
            "      snake\n",
            "      Gerland!               attentive\n",
            "      maledictions\n",
            "      frown\n",
            "      fornication!\n",
            "\n",
            "           948\n",
            "      Filth\n",
            "      foreshow\n",
            "      alacke\n",
            "      specialties\n",
            "      affied\n",
            "      rifted\n",
            "      duchyunpossessingprophetess\n",
            "      complainer!\n",
            "\n",
            "           948\n",
            "      smug\n",
            "      Filth\n",
            "      unarmd\n",
            "      foreshow\n",
            "      lover\n",
            "      lover\n",
            "      specialties\n",
            "      frown\n",
            "      imagine\n",
            "SON\n",
            "      pupil\n",
            "      forfeited\n",
            "      coppice\n",
            "      affied\n",
            "      cygnets\n",
            "      rifted\n",
            "      interchang\n",
            "      golden\n",
            "      frown\n",
            "      fornication.]\n",
            "948\n",
            "      rifted\n",
            "      likeliest\n",
            "      ros!\n",
            "               Filth\n",
            "      currance\n",
            "      lover!\n",
            "\n",
            "           Roughly\n",
            "      Filth\n",
            "      foreshow\n",
            "      escapt\n",
            "      frown\n",
            "      mered\n",
            "      dragon\n",
            "      smug\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            ";              \n",
            "      forfeited\n",
            "      smug\n",
            "      foreigner\n",
            "      alacke\n",
            "      inhooped\n",
            "      snake\n",
            "      clocks\n",
            "Roughly\n",
            "      hatefully\n",
            "      hasten\n",
            "      looks\n",
            "      lean\n",
            "      golden\n",
            "      soit\n",
            "      companies\n",
            "      smug\n",
            "      Filth\n",
            "      foreshow\n",
            "      forgot!\n",
            "               loureth\n",
            "      snake\n",
            "      matches\n",
            "      maledictions\n",
            "      snake\n",
            "undraws!\n",
            "               Filth\n",
            "unfilial\n",
            "      affied\n",
            "      lover\n",
            "      foreshow\n",
            "      cygnets\n",
            "      envied\n",
            "      snake\n",
            "      throughout\n",
            "      fornication.—\n",
            "\n",
            "[snake\n",
            "      Gerland\n",
            "LORDS\n",
            "      Varrius\n",
            "      sobs\n",
            "      maledictions\n",
            "      likeliest\n",
            "      commonwealth!\n",
            "               Filthunpossessingimpudique\n",
            "      banks\n",
            "      snaky\n",
            "specialties\n",
            "      unluckily!\n",
            "               _Bosko\n",
            "      sleight\n",
            "      ista\n",
            "      snaky!\n",
            "               _Bosko\n",
            "      unlicensed\n",
            "unarmd\n",
            "      inside\n",
            "      ista!—Filth\n",
            "      foreshow\n",
            "                                   deputies\n",
            "      envied\n",
            "      Varrius\n",
            "      insufficience!—Bestowed!\n",
            "               Filthunpossessingimpudique\n",
            "      lover\n",
            "      feasted\n",
            "      likeliest\n",
            "      indulgent!\n",
            "\n",
            "           Filth\n",
            "      unarmd\n",
            "      affied\n",
            "      lover\n",
            "      envied\n",
            "      hatefully\n",
            "      hasten!\n",
            "               loureth\n",
            "      snake\n",
            "      undraws!\n",
            "\n",
            "           948\n",
            "      giftes\n",
            "      unluckily\n",
            "      foreshow\n",
            "      foreshow\n",
            "      rak\n",
            "      friskins\n",
            "      rifted\n",
            "      robustious\n",
            "      golden\n",
            "      likeliest\n",
            "      gardez!\n",
            "               _Bosko\n",
            "      Filth\n",
            "      unfilial\n",
            "inside\n",
            "      unluckily\n",
            "      specialties\n",
            "      railer\n",
            "      unluckily\n",
            "      maledictions\n",
            "      snake\n",
            "      chirurgeonly\n",
            "      sowl\n",
            "      maledictions\n",
            "      soit\n",
            "      fees\n",
            "lolls!\n",
            "               Filth\n",
            "      recanter\n",
            "      affied\n",
            "      feels\n",
            "      Varrius\n",
            "      fees.—\n",
            "\n",
            "[envied\n",
            "      soit\n",
            "      insufficience\n",
            "      maledictions\n",
            "      smug\n",
            "      Filth\n",
            "      foreshow\n",
            "      cygnets\n",
            "Rous\n",
            "      fees\n",
            "      sowl\n",
            "      maledictions\n",
            "      unmask\n",
            "      fluxive\n",
            "      _Puts\n",
            "      _Sweet\n",
            "Varrius\n",
            "      insufficience\n",
            "      maledictions\n",
            "      frown\n",
            "      durance!—Argier\n",
            "      hatefully\n",
            "      affied\n",
            "      lover\n",
            "      golden\n",
            "      snake\n",
            "      deifies\n",
            "maledictions\n",
            "      frown\n",
            "      indulgent!\n",
            "               marrowless!\n",
            "               forfeited\n",
            "      unarmd\n",
            "      lover\n",
            "      affied\n",
            "      rifted!                   Crams\n",
            "      snake\n",
            "      Gerland\n",
            "      smug\n",
            "      forfeited\n",
            "      hasten\n",
            "      rifted\n",
            "      lessen\n",
            "SON\n",
            "      affied\n",
            "      Varrius\n",
            "      heroical!\n",
            "               snake\n",
            "      undraws\n",
            "      unarmd\n",
            "      lover\n",
            "      affied!                   ?’\n",
            "\n",
            "!                  Spur!\n",
            "               Filth\n",
            "      currance\n",
            "      railer\n",
            "      snaky\n",
            "      garter\n",
            "      hatefully1069Stain\n",
            "      unfilial\n",
            "      soldiership\n",
            "      societies1Fitting\n",
            "      soldiership\n",
            "      forceful\n",
            "      lover\n",
            "      sounded\n",
            "      fornication!\n",
            "               soldiership\n",
            "      regreetsunpossessingsarcenet\n",
            "      soldiership\n",
            "      daintier!                   Assail!                  Filth\n",
            "      foreshow\n",
            "      alacke\n",
            "      specialties\n",
            "      snake\n",
            "      Gerland\n",
            "      maledictions\n",
            "      hatefully1069French\n",
            "1164\n",
            "      fees\n",
            "      insufficience.—\n",
            "\n",
            "[beautify\n",
            "      soldiership\n",
            "      unaware\n",
            "      embroidery\n",
            "      sounder\n",
            "      soldiership\n",
            "      daintier\n",
            "      lover\n",
            "      soldiership\n",
            "      lover\n",
            "      lover\n",
            "      embroidery!\n",
            "\n",
            "           Lamentable\n",
            "      soldiership\n",
            "      affied\n",
            "      lover\n",
            "      smug\n",
            "      soldiership\n",
            "      forceful\n",
            "      lover\n",
            "      lover\n",
            "      lover\n",
            "      specialties\n",
            "      ista\n",
            "      railer\n",
            "      sounded\n",
            "      indulgent!\n",
            "\n",
            "           948\n",
            "      smug\n",
            "      likeliest\n",
            "      ros\n",
            "      hasten\n",
            "      looks\n",
            "      lean\n",
            "      lean\n",
            "      golden\n",
            "      snake\n",
            "      undrawsunpossessingprophetess\n",
            "      forfeiters!                   Garlands\n",
            "      Lenten!                  Stain\n",
            "      daintier\n",
            "      soldiership\n",
            "      lover\n",
            "      lover\n",
            "      pupil!\n",
            "               soldiershipunpossessingsarcenet\n",
            "      soldiership\n",
            "      Varrius\n",
            "      sprited!\n",
            "\n",
            "           948\n",
            "      unlicensed\n",
            "      soldiership\n",
            "      forceful\n",
            "      Varrius\n",
            "      filed\n",
            "      sobs\n",
            "      Filth\n",
            "      foreshow\n",
            "      snaky!                  Argier\n",
            "      soldiership\n",
            "      copulation\n",
            "      lover\n",
            "      sounded\n",
            "      imagine\n",
            "      Filth\n",
            "      hips!                  Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      lover\n",
            "      rifted\n",
            "      incontinently\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      Filth\n",
            "      ]\n",
            "\n",
            "[\n",
            "      Varrius\n",
            "      entomb\n",
            "      envied\n",
            "      sounded\n",
            "      gentler!\n",
            "               smug\n",
            "Filth\n",
            "      unarmd\n",
            "      fare\n",
            "      snaky\n",
            "      Varrius\n",
            "      undistinguish\n",
            "      specialties\n",
            "      affied\n",
            "      Varrius\n",
            "      insufficience\n",
            "      smug\n",
            "      Filth\n",
            "      foreshow!\n",
            "               _Bosko\n",
            "      sleight\n",
            "friskins\n",
            "      envied\n",
            "      soit!—HASTINGS\n",
            "      ista\n",
            "      affied\n",
            "      snake\n",
            "      convents\n",
            "      smug\n",
            "      Filth\n",
            "      unfilial\n",
            "      foreshow\n",
            "      alacke\n",
            "      Varrius\n",
            "      insufficienceunpossessingprophetess\n",
            "      complainer\n",
            "golden\n",
            "      sounded\n",
            "      durance\n",
            "      _Bosko\n",
            "      likeliest\n",
            "      indulgent\n",
            "      unarmd\n",
            "      inside\n",
            "sounded\n",
            "      durance!—Stain\n",
            "      unarmd!\n",
            "               soldiership\n",
            "      forceful\n",
            "      soldiership\n",
            "      _Squeezes\n",
            "      lover101634!                  Filth\n",
            "      societies\n",
            "      Filthunpossessingimpudique\n",
            "      foreshow\n",
            "      snaky\n",
            "      specialties\n",
            "      ista!                   Crams\n",
            "      Varrius\n",
            "      Imprison!                   February\n",
            "      lui1069Knowes\n",
            "      _Squeezes\n",
            "      soldiership\n",
            "      soldiership!\n",
            "               likeliest\n",
            "      indexes!\n",
            "               Filthunpossessingimpudique\n",
            "      affied\n",
            "      rifted\n",
            "      _Sweet\n",
            "      Filth\n",
            "      currance!                  Fitting\n",
            "      soldiership\n",
            "      unfill\n",
            "      affied\n",
            "      lover\n",
            "’HASTINGS\n",
            "      snarl\n",
            "      railer\n",
            "      likeliest\n",
            "      indexes\n",
            "SON\n",
            "      affied\n",
            "      lover!                   LAVINIA!                  Stain\n",
            "      _Squeezes\n",
            "      soldiership!\n",
            "               Filth\n",
            "      foreshow\n",
            "      looks\n",
            "      hurts\n",
            "      specialties\n",
            "      rudeness\n",
            "948\n",
            "      Filth\n",
            "      foreshow\n",
            "      Varrius\n",
            "      insufficience!—Filth\n",
            "      unarmd\n",
            "      foreshow\n",
            "      lover\n",
            "      lover\n",
            "      affied\n",
            "      rifted.]\n",
            "Argier\n",
            "      soldiership\n",
            "      unaware\n",
            "      rudeness\n",
            "      specialties\n",
            "      snake\n",
            "      undraws\n",
            "      maledictions\n",
            "      snake\n",
            "      Gerland\n",
            "      maledictions\n",
            "      soit\n",
            "      undrawsunpossessingprophetess\n",
            "      complainer!                  Stain\n",
            "      hasten!\n",
            "               _Bosko\n",
            "      sounded\n",
            "      fornication\n",
            "      soldiership\n",
            "      _Squeezes\n",
            "      sounded\n",
            "      durance10Mousetrap\n",
            "      Hereditary\n",
            "      Constrains!                  Knowes\n",
            "      smug\n",
            "      hasten\n",
            "      hatefully\n",
            "      rifted\n",
            "      snake\n",
            "      undraws!\n",
            "               forfeited\n",
            "      coppice\n",
            "      lover\n",
            "      lover\n",
            "      railer\n",
            "      snaky!                  Filthunpossessingimpudique\n",
            "      fare\n",
            "      hatefully!\n",
            "               envied\n",
            "      sounded\n",
            "      indulgent!\n",
            "               specialties\n",
            "      copulatives\n",
            "      sounded\n",
            "      forfeiters\n",
            "Filth\n",
            "      currance\n",
            "      Filth\n",
            "      railer\n",
            "      snaky\n",
            "      maledictions\n",
            "      snaky!\n",
            "               envied\n",
            "      soldiership\n",
            "      _Squeezes\n",
            "      sounded\n",
            "      durance!                  Iwis\n",
            "      durance\n",
            "      recanter\n",
            "      inside\n",
            "      likeliest\n",
            "      indulgent!\n",
            "               Filth\n",
            "      hips\n",
            "      lover\n",
            "      ista1Fitting\n",
            "      Filth\n",
            "      beguiled\n",
            "      affied.—\n",
            "\n",
            "[envied\n",
            "      Filth\n",
            "      societies\n",
            "      likeliest\n",
            "      invis\n",
            "      smug\n",
            "      likeliest\n",
            "      durance!\n",
            "\n",
            "           Fitting\n",
            "      hatefully\n",
            "      affied\n",
            "      sounded\n",
            "      invis\n",
            "      affied\n",
            "      lover\n",
            "      Varrius\n",
            "      underborne!                   149!                  Stocking\n",
            "      daintier\n",
            "      soldiership\n",
            "      lover\n",
            "      foreshow\n",
            "      alacke\n",
            "      Varrius\n",
            "      fees\n",
            "      durance\n",
            "      specialties\n",
            "      affied\n",
            "      rifted!—Fitting\n",
            "Rous\n",
            "      undraws\n",
            "      unarmd\n",
            "      Filthunpossessingimpudique\n",
            "      rudeness\n",
            "      unchaste\n",
            "      friskins!\n",
            "               Filth\n",
            "      foreshow\n",
            "      rak\n",
            "      hatefully!                  Filth\n",
            "      unfilial\n",
            "      Filth\n",
            "      foreshow\n",
            "      cygnets\n",
            "      likeliest\n",
            "      indexes!\n",
            "               _Bosko\n",
            "      forfeited\n",
            "      treasons\n",
            "      snake\n",
            "      animis\n",
            "      golden!\n",
            "\n",
            "           948\n",
            "      Filth\n",
            "      regions\n",
            "      foreshow\n",
            "      likeliest\n",
            "      ros\n",
            "      specialties\n",
            "      affied\n",
            "      feels!                   Mutes!                  Filth\n",
            "      unfilial\n",
            "      foreshow\n",
            "      Varrius\n",
            "      entomb\n",
            "      specialtiesunpossessingsimpleness!\n",
            "               Filth\n",
            "      currance\n",
            "      hips\n",
            "Rous\n",
            "      lean!\n",
            "               Filthunpossessingimpudique\n",
            "      fare\n",
            "      snaky\n",
            "      envied\n",
            "      ista\n"
          ]
        }
      ],
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "context = \" O God, O God! \"\n",
        "x = torch.tensor([train_dataset.stoi[s] for s in re.split(r\"\\b\", context)], dtype=torch.long)[None,...].to(device)\n",
        "y = sample(model, x, 5500, temperature=1.0, sample=True, top_k=10)[0]\n",
        "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
        "print(completion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYAAehkwxGjW"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpaa_98GwxH2",
        "outputId": "76c9295a-dd8f-4073-e0cb-8421b3027c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  O God, O God! O heavens; that you do not say he is\n",
            "not.\n",
            "Sentiment: Positive\n",
            "\n",
            "Sentence: \n",
            "DESDEMONA.\n",
            "Sentiment: Neutral\n",
            "\n",
            "Sentence: But now, what is your Grace.\n",
            "Sentiment: Positive\n",
            "\n",
            "Sentence: \n",
            "EMILIA.\n",
            "Sentiment: Neutral\n",
            "\n",
            "Sentence: I have been so good to my mistress.\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_path = 'classified_sentences.txt'\n",
        "with open(output_path, 'r', encoding='utf-8') as file:\n",
        "    classified = eval(file.read())\n",
        "\n",
        "# Print the classified sentences\n",
        "for sentence, sentiment in classified[:5]:\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    if sentiment == 1:\n",
        "        print(\"Sentiment: Positive\")\n",
        "    elif sentiment == 2:\n",
        "        print(\"Sentiment: Negative\")\n",
        "    else:\n",
        "        print(\"Sentiment: Neutral\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvqKSLrrx_KD"
      },
      "source": [
        "Fine-tune your model to obtain a reward model that predicts the sentiment of a sample. You can treat this as a sequence-modeling problem by having a model predict special tokens such as \"happy\" and \"sad\" based on the sentiment, treating neutral labels as soft 50% labels. Remember to mask all but the last token of the sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "mbGCfdf8x-VM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class SentimentTransformerDecoderOnly(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, num_layers, dropout=0.1):\n",
        "        super(SentimentTransformerDecoderOnly, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.decoder = Decoder(d_model, num_heads, num_layers, dropout)\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "        self.sentiment_head = nn.Linear(d_model, 3)  # Predict positive, negative, neutral\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_enc(x)\n",
        "        x = self.decoder(x, mask)\n",
        "        logits = self.linear(x)\n",
        "        sentiment_logits = self.sentiment_head(x[:, -1, :])  # Use the last token's representation\n",
        "        return logits, sentiment_logits\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, data, labels, block_size, stoi, itos):\n",
        "        # words = re.split(r\"\\b\", data)\n",
        "        self.stoi = stoi\n",
        "        self.itos = itos\n",
        "        self.block_size = block_size\n",
        "        self.vocab_size = len(stoi)\n",
        "        self.labels = labels\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chunk = self.data[idx:idx + self.block_size + 1]\n",
        "        dix = [self.stoi[s] for s in chunk]\n",
        "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "e5cSMwVF4RTf"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "sentences, sentiments = [], []\n",
        "for sentence, sentiment in classified:\n",
        "    sentences.append(sentence)\n",
        "    sentiments.append(sentiment)\n",
        "\n",
        "# split sentences in train and test\n",
        "fraction_train = 0.8\n",
        "num_train = int(len(sentences) * fraction_train)\n",
        "sentences_train, sentences_test = sentences[:num_train], sentences[num_train:]\n",
        "sentiments_train, sentiments_test = sentiments[:num_train], sentiments[num_train:]\n",
        "\n",
        "print(len(sentences_train), len(sentences_test))\n",
        "\n",
        "# add sentences and labels to dataset\n",
        "train_dataset = SentimentDataset(sentences_train, sentiments_train, block_size, train_dataset.stoi, train_dataset.itos)\n",
        "test_dataset = SentimentDataset(sentences_test, sentiments_test, block_size, train_dataset.stoi, train_dataset.itos)\n",
        "\n",
        "# create data loaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, shuffle=True, pin_memory=True, batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, shuffle=False, pin_memory=True, batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oic04zbd4v3x",
        "outputId": "c2e1ebd7-471d-4b94-fd03-d34a1049c72b"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab_size_sent = len(train_dataset.stoi)\n",
        "d_model_sent = 512\n",
        "num_heads_sent = 8\n",
        "num_layers_sent = 6\n",
        "dropout_sent = 0.1\n",
        "\n",
        "# Instantiate the model\n",
        "model_sent = SentimentTransformerDecoderOnly(vocab_size_sent, d_model_sent, num_heads_sent, num_layers_sent, dropout_sent)\n",
        "\n",
        "# Define optimizer and loss criterion\n",
        "optimizer_sent = torch.optim.Adam(model_sent.parameters(), lr=1e-4)\n",
        "criterion_sent = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "model_sent.train()\n",
        "for epoch in range(1):\n",
        "    for input_ids_sent, label_sent in train_loader:\n",
        "        optimizer_sent.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        logits_sent, sentiment_logits_sent = model_sent(input_ids_sent, mask=None)\n",
        "\n",
        "        # Compute loss\n",
        "        loss_sent = criterion_sent(sentiment_logits_sent, label_sent)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss_sent.backward()\n",
        "        optimizer_sent.step()\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Loss: {loss_sent.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "5j7WYbT2bdTN",
        "outputId": "aab6f151-bccb-48a2-c3b3-de786d69be91"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'How now?'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-2339510e487b>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minput_ids_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_sent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-7d5327f17b60>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-7d5327f17b60>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'How now?'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dll7KNYi4VXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PPO\n",
        "\n",
        "Source: https://github.com/ckkissane/deep_learning_curriculum/blob/master/solutions/6_Reinforcement_Learning.ipynb"
      ],
      "metadata": {
        "id": "JKvZRK2lx6vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install procgen"
      ],
      "metadata": {
        "id": "4Aw4Ta4KyL-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "import gym\n",
        "from gym import spaces\n",
        "from procgen import ProcgenEnv\n",
        "import random\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "from abc import ABC, abstractmethod\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9EM_uHZ1x7-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_global_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "class Storage():\n",
        "\n",
        "    def __init__(self, obs_shape, num_steps, num_envs, device):\n",
        "        self.obs_shape = obs_shape\n",
        "        self.num_steps = num_steps\n",
        "        self.num_envs = num_envs\n",
        "        self.device = device\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.obs_batch = torch.zeros(self.num_steps+1, self.num_envs, *self.obs_shape)\n",
        "        self.act_batch = torch.zeros(self.num_steps, self.num_envs)\n",
        "        self.rew_batch = torch.zeros(self.num_steps, self.num_envs)\n",
        "        self.done_batch = torch.zeros(self.num_steps, self.num_envs)\n",
        "        self.log_prob_act_batch = torch.zeros(self.num_steps, self.num_envs)\n",
        "        self.value_batch = torch.zeros(self.num_steps+1, self.num_envs)\n",
        "        self.return_batch = torch.zeros(self.num_steps, self.num_envs)\n",
        "        self.adv_batch = torch.zeros(self.num_steps, self.num_envs)\n",
        "        self.info_batch = deque(maxlen=self.num_steps)\n",
        "        self.step = 0\n",
        "\n",
        "    def store(self, obs, act, rew, done, info, log_prob_act, value):\n",
        "        self.obs_batch[self.step] = torch.from_numpy(obs.copy())\n",
        "        self.act_batch[self.step] = torch.from_numpy(act.copy())\n",
        "        self.rew_batch[self.step] = torch.from_numpy(rew.copy())\n",
        "        self.done_batch[self.step] = torch.from_numpy(done.copy())\n",
        "        self.log_prob_act_batch[self.step] = torch.from_numpy(log_prob_act.copy())\n",
        "        self.value_batch[self.step] = torch.from_numpy(value.copy())\n",
        "        self.info_batch.append(info)\n",
        "\n",
        "        self.step = (self.step + 1) % self.num_steps\n",
        "\n",
        "    def store_last(self, last_obs, last_value):\n",
        "        self.obs_batch[-1] = torch.from_numpy(last_obs.copy())\n",
        "        self.value_batch[-1] = torch.from_numpy(last_value.copy())\n",
        "\n",
        "    def compute_estimates(self, gamma=0.99, lmbda=0.95):\n",
        "        rew_batch = self.rew_batch\n",
        "        # use_gae\n",
        "        A = 0\n",
        "        for i in reversed(range(self.num_steps)):\n",
        "            rew = rew_batch[i]\n",
        "            done = self.done_batch[i]\n",
        "            value = self.value_batch[i]\n",
        "            next_value = self.value_batch[i+1]\n",
        "\n",
        "            delta = (rew + gamma * next_value * (1 - done)) - value\n",
        "            self.adv_batch[i] = A = gamma * lmbda * A * (1 - done) + delta\n",
        "\n",
        "        self.return_batch = self.adv_batch + self.value_batch[:-1]\n",
        "        # normalize_adv\n",
        "        adv_mean = torch.mean(self.adv_batch)\n",
        "        adv_std = torch.std(self.adv_batch)\n",
        "        print(f\"adv_mean: {adv_mean}\")\n",
        "        print(f\"adv_std: {adv_std}\")\n",
        "        self.adv_batch = (self.adv_batch - adv_mean) / (adv_std + 1e-8)\n",
        "\n",
        "\n",
        "    def fetch_train_generator(self, mini_batch_size=None):\n",
        "        batch_size = self.num_steps * self.num_envs\n",
        "        if mini_batch_size is None:\n",
        "            mini_batch_size = batch_size\n",
        "        sampler = BatchSampler(SubsetRandomSampler(range(batch_size)),\n",
        "                                mini_batch_size,\n",
        "                                drop_last=True)\n",
        "        for indices in sampler:\n",
        "            obs_batch = torch.FloatTensor(self.obs_batch[:-1]).reshape(-1, *self.obs_shape)[indices].to(self.device)\n",
        "            act_batch = torch.FloatTensor(self.act_batch).reshape(-1)[indices].to(self.device)\n",
        "            done_batch = torch.FloatTensor(self.done_batch).reshape(-1)[indices].to(self.device)\n",
        "            log_prob_act_batch = torch.FloatTensor(self.log_prob_act_batch).reshape(-1)[indices].to(self.device)\n",
        "            value_batch = torch.FloatTensor(self.value_batch[:-1]).reshape(-1)[indices].to(self.device)\n",
        "            return_batch = torch.FloatTensor(self.return_batch).reshape(-1)[indices].to(self.device)\n",
        "            adv_batch = torch.FloatTensor(self.adv_batch).reshape(-1)[indices].to(self.device)\n",
        "            yield obs_batch, act_batch, done_batch, log_prob_act_batch, value_batch, return_batch, adv_batch\n",
        "\n",
        "    def fetch_log_data(self):\n",
        "        if 'env_reward' in self.info_batch[0][0]:\n",
        "            rew_batch = []\n",
        "            for step in range(self.num_steps):\n",
        "                infos = self.info_batch[step]\n",
        "                rew_batch.append([info['env_reward'] for info in infos])\n",
        "            rew_batch = np.array(rew_batch)\n",
        "        else:\n",
        "            rew_batch = self.rew_batch.numpy()\n",
        "        if 'env_done' in self.info_batch[0][0]:\n",
        "            done_batch = []\n",
        "            for step in range(self.num_steps):\n",
        "                infos = self.info_batch[step]\n",
        "                done_batch.append([info['env_done'] for info in infos])\n",
        "            done_batch = np.array(done_batch)\n",
        "        else:\n",
        "            done_batch = self.done_batch.numpy()\n",
        "        return rew_batch, done_batch\n",
        "\n"
      ],
      "metadata": {
        "id": "ij2FN-Rbx_T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logger"
      ],
      "metadata": {
        "id": "hwpY9ezbybkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Logger(object):\n",
        "\n",
        "    def __init__(self, n_envs, logdir):\n",
        "        self.start_time = time.time()\n",
        "        self.n_envs = n_envs\n",
        "        self.logdir = logdir\n",
        "\n",
        "        self.episode_rewards = []\n",
        "        for _ in range(n_envs):\n",
        "            self.episode_rewards.append([])\n",
        "        self.episode_len_buffer = deque(maxlen = 40)\n",
        "        self.episode_reward_buffer = deque(maxlen = 40)\n",
        "\n",
        "        self.log = pd.DataFrame(columns = ['timesteps', 'wall_time', 'num_episodes',\n",
        "                               'max_episode_rewards', 'mean_episode_rewards','min_episode_rewards',\n",
        "                               'max_episode_len', 'mean_episode_len', 'min_episode_len'])\n",
        "        self.timesteps = 0\n",
        "        self.num_episodes = 0\n",
        "\n",
        "    def feed(self, rew_batch, done_batch):\n",
        "        steps = rew_batch.shape[0]\n",
        "        rew_batch = rew_batch.T\n",
        "        done_batch = done_batch.T\n",
        "\n",
        "        for i in range(self.n_envs):\n",
        "            for j in range(steps):\n",
        "                self.episode_rewards[i].append(rew_batch[i][j])\n",
        "                if done_batch[i][j]:\n",
        "                    self.episode_len_buffer.append(len(self.episode_rewards[i]))\n",
        "                    self.episode_reward_buffer.append(np.sum(self.episode_rewards[i]))\n",
        "                    self.episode_rewards[i] = []\n",
        "                    self.num_episodes += 1\n",
        "        self.timesteps += (self.n_envs * steps)\n",
        "\n",
        "    def write_summary(self, summary):\n",
        "        for key, value in summary.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "    def dump(self):\n",
        "        wall_time = time.time() - self.start_time\n",
        "        if self.num_episodes > 0:\n",
        "            episode_statistics = self._get_episode_statistics()\n",
        "            episode_statistics_list = list(episode_statistics.values())\n",
        "        else:\n",
        "            episode_statistics_list = [None] * 6\n",
        "        log = [self.timesteps] + [wall_time] + [self.num_episodes] + episode_statistics_list\n",
        "        self.log.loc[len(self.log)] = log\n",
        "\n",
        "        with open(self.logdir + '/log.csv', 'w') as f:\n",
        "            self.log.to_csv(f, index = False)\n",
        "        print(self.log.loc[len(self.log)-1])\n",
        "\n",
        "    def _get_episode_statistics(self):\n",
        "        episode_statistics = {}\n",
        "        episode_statistics['Rewards/max_episodes']  = np.max(self.episode_reward_buffer)\n",
        "        episode_statistics['Rewards/mean_episodes'] = np.mean(self.episode_reward_buffer)\n",
        "        episode_statistics['Rewards/min_episodes']  = np.min(self.episode_reward_buffer)\n",
        "        episode_statistics['Len/max_episodes']  = np.max(self.episode_len_buffer)\n",
        "        episode_statistics['Len/mean_episodes'] = np.mean(self.episode_len_buffer)\n",
        "        episode_statistics['Len/min_episodes']  = np.min(self.episode_len_buffer)\n",
        "        return episode_statistics\n"
      ],
      "metadata": {
        "id": "K_lnwCsOyhDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Impala"
      ],
      "metadata": {
        "id": "CZpCsIzQylp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(x)\n",
        "        out = self.conv1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        return out + x\n",
        "\n",
        "class ImpalaBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.res1 = ResidualBlock(out_channels)\n",
        "        self.res2 = ResidualBlock(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x)\n",
        "        return x\n",
        "\n",
        "class ImpalaModel(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.block1 = ImpalaBlock(in_channels=in_channels, out_channels=16)\n",
        "        self.block2 = ImpalaBlock(in_channels=16, out_channels=32)\n",
        "        self.block3 = ImpalaBlock(in_channels=32, out_channels=32)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(in_features=32 * 8 * 8, out_features=256)\n",
        "\n",
        "        self.output_dim = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = F.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4TFF2l7fym7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CategoricalPolicy(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embedder,\n",
        "                 action_size):\n",
        "        \"\"\"\n",
        "        embedder: (torch.Tensor) model to extract the embedding for observation\n",
        "        action_size: number of the categorical actions\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embedder = embedder\n",
        "        self.fc_policy = nn.Linear(self.embedder.output_dim, action_size)\n",
        "        self.fc_value = nn.Linear(self.embedder.output_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.embedder(x)\n",
        "        logits = self.fc_policy(hidden)\n",
        "        p = Categorical(logits=logits)\n",
        "        v = self.fc_value(hidden).reshape(-1)\n",
        "        return p, v\n",
        ""
      ],
      "metadata": {
        "id": "uFT9xou_yqbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7trPGA_QBloV"
      },
      "source": [
        "<!--  -->"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "See https://github.com/openai/baselines/tree/master/baselines/common/vec_env\n",
        "\"\"\"\n",
        "\n",
        "class VecEnv(ABC):\n",
        "    \"\"\"\n",
        "    An abstract asynchronous, vectorized environment.\n",
        "    Used to batch data from multiple copies of an environment, so that\n",
        "    each observation becomes an batch of observations, and expected action is a batch of actions to\n",
        "    be applied per-environment.\n",
        "    \"\"\"\n",
        "    closed = False\n",
        "    viewer = None\n",
        "\n",
        "    metadata = {\n",
        "        'render.modes': ['human', 'rgb_array']\n",
        "    }\n",
        "\n",
        "    def __init__(self, num_envs, observation_space, action_space):\n",
        "        self.num_envs = num_envs\n",
        "        self.observation_space = observation_space\n",
        "        self.action_space = action_space\n",
        "\n",
        "    @abstractmethod\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset all the environments and return an array of\n",
        "        observations, or a dict of observation arrays.\n",
        "        If step_async is still doing work, that work will\n",
        "        be cancelled and step_wait() should not be called\n",
        "        until step_async() is invoked again.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def step_async(self, actions):\n",
        "        \"\"\"\n",
        "        Tell all the environments to start taking a step\n",
        "        with the given actions.\n",
        "        Call step_wait() to get the results of the step.\n",
        "        You should not call this if a step_async run is\n",
        "        already pending.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def step_wait(self):\n",
        "        \"\"\"\n",
        "        Wait for the step taken with step_async().\n",
        "        Returns (obs, rews, dones, infos):\n",
        "         - obs: an array of observations, or a dict of\n",
        "                arrays of observations.\n",
        "         - rews: an array of rewards\n",
        "         - dones: an array of \"episode done\" booleans\n",
        "         - infos: a sequence of info objects\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def close_extras(self):\n",
        "        \"\"\"\n",
        "        Clean up the  extra resources, beyond what's in this base class.\n",
        "        Only runs when not self.closed.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        if self.closed:\n",
        "            return\n",
        "        if self.viewer is not None:\n",
        "            self.viewer.close()\n",
        "        self.close_extras()\n",
        "        self.closed = True\n",
        "\n",
        "    def step(self, actions):\n",
        "        \"\"\"\n",
        "        Step the environments synchronously.\n",
        "        This is available for backwards compatibility.\n",
        "        \"\"\"\n",
        "        self.step_async(actions)\n",
        "        return self.step_wait()\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        imgs = self.get_images()\n",
        "        bigimg = \"ARGHH\" #tile_images(imgs)\n",
        "        if mode == 'human':\n",
        "            self.get_viewer().imshow(bigimg)\n",
        "            return self.get_viewer().isopen\n",
        "        elif mode == 'rgb_array':\n",
        "            return bigimg\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def get_images(self):\n",
        "        \"\"\"\n",
        "        Return RGB images from each environment\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    def unwrapped(self):\n",
        "        if isinstance(self, VecEnvWrapper):\n",
        "            return self.venv.unwrapped\n",
        "        else:\n",
        "            return self\n",
        "\n",
        "    def get_viewer(self):\n",
        "        if self.viewer is None:\n",
        "            from gym.envs.classic_control import rendering\n",
        "            self.viewer = rendering.SimpleImageViewer()\n",
        "        return self.viewer\n",
        "\n",
        "\n",
        "class VecEnvWrapper(VecEnv):\n",
        "    \"\"\"\n",
        "    An environment wrapper that applies to an entire batch\n",
        "    of environments at once.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, venv, observation_space=None, action_space=None):\n",
        "        self.venv = venv\n",
        "        super().__init__(num_envs=venv.num_envs,\n",
        "                        observation_space=observation_space or venv.observation_space,\n",
        "                        action_space=action_space or venv.action_space)\n",
        "\n",
        "    def step_async(self, actions):\n",
        "        self.venv.step_async(actions)\n",
        "\n",
        "    @abstractmethod\n",
        "    def reset(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def step_wait(self):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        return self.venv.close()\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.venv.render(mode=mode)\n",
        "\n",
        "    def get_images(self):\n",
        "        return self.venv.get_images()\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        if name.startswith('_'):\n",
        "            raise AttributeError(\"attempted to get missing private attribute '{}'\".format(name))\n",
        "        return getattr(self.venv, name)\n",
        "\n",
        "\n",
        "class VecEnvObservationWrapper(VecEnvWrapper):\n",
        "    @abstractmethod\n",
        "    def process(self, obs):\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        obs = self.venv.reset()\n",
        "        return self.process(obs)\n",
        "\n",
        "    def step_wait(self):\n",
        "        obs, rews, dones, infos = self.venv.step_wait()\n",
        "        return self.process(obs), rews, dones, infos\n",
        "\n",
        "\n",
        "class VecExtractDictObs(VecEnvObservationWrapper):\n",
        "    def __init__(self, venv, key):\n",
        "        self.key = key\n",
        "        super().__init__(venv=venv,\n",
        "            observation_space=venv.observation_space.spaces[self.key])\n",
        "\n",
        "    def process(self, obs):\n",
        "        return obs[self.key]\n",
        "\n",
        "\n",
        "class RunningMeanStd(object):\n",
        "    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n",
        "    def __init__(self, epsilon=1e-4, shape=()):\n",
        "        self.mean = np.zeros(shape, 'float64')\n",
        "        self.var = np.ones(shape, 'float64')\n",
        "        self.count = epsilon\n",
        "\n",
        "    def update(self, x):\n",
        "        batch_mean = np.mean(x, axis=0)\n",
        "        batch_var = np.var(x, axis=0)\n",
        "        batch_count = x.shape[0]\n",
        "        self.update_from_moments(batch_mean, batch_var, batch_count)\n",
        "\n",
        "    def update_from_moments(self, batch_mean, batch_var, batch_count):\n",
        "        self.mean, self.var, self.count = update_mean_var_count_from_moments(\n",
        "            self.mean, self.var, self.count, batch_mean, batch_var, batch_count)\n",
        "\n",
        "\n",
        "def update_mean_var_count_from_moments(mean, var, count, batch_mean, batch_var, batch_count):\n",
        "    delta = batch_mean - mean\n",
        "    tot_count = count + batch_count\n",
        "\n",
        "    new_mean = mean + delta * batch_count / tot_count\n",
        "    m_a = var * count\n",
        "    m_b = batch_var * batch_count\n",
        "    M2 = m_a + m_b + np.square(delta) * count * batch_count / tot_count\n",
        "    new_var = M2 / tot_count\n",
        "    new_count = tot_count\n",
        "\n",
        "    return new_mean, new_var, new_count\n",
        "\n",
        "\n",
        "class VecNormalize(VecEnvWrapper):\n",
        "    \"\"\"\n",
        "    A vectorized wrapper that normalizes the observations\n",
        "    and returns from an environment.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, venv, ob=True, ret=True, clipob=10., cliprew=10., gamma=0.99, epsilon=1e-8):\n",
        "        VecEnvWrapper.__init__(self, venv)\n",
        "\n",
        "        self.ob_rms = RunningMeanStd(shape=self.observation_space.shape) if ob else None\n",
        "        self.ret_rms = RunningMeanStd(shape=()) if ret else None\n",
        "\n",
        "        self.clipob = clipob\n",
        "        self.cliprew = cliprew\n",
        "        self.ret = np.zeros(self.num_envs)\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def step_wait(self):\n",
        "        obs, rews, news, infos = self.venv.step_wait()\n",
        "        for i in range(len(infos)):\n",
        "            infos[i]['env_reward'] = rews[i]\n",
        "        self.ret = self.ret * self.gamma + rews\n",
        "        obs = self._obfilt(obs)\n",
        "        if self.ret_rms:\n",
        "            self.ret_rms.update(self.ret)\n",
        "            rews = np.clip(rews / np.sqrt(self.ret_rms.var + self.epsilon), -self.cliprew, self.cliprew)\n",
        "        self.ret[news] = 0.\n",
        "        return obs, rews, news, infos\n",
        "\n",
        "    def _obfilt(self, obs):\n",
        "        if self.ob_rms:\n",
        "            self.ob_rms.update(obs)\n",
        "            obs = np.clip((obs - self.ob_rms.mean) / np.sqrt(self.ob_rms.var + self.epsilon), -self.clipob, self.clipob)\n",
        "            return obs\n",
        "        else:\n",
        "            return obs\n",
        "\n",
        "    def reset(self):\n",
        "        self.ret = np.zeros(self.num_envs)\n",
        "        obs = self.venv.reset()\n",
        "        return self._obfilt(obs)\n",
        "\n",
        "\n",
        "class TransposeFrame(VecEnvWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(venv=env)\n",
        "        obs_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(obs_shape[2], obs_shape[0], obs_shape[1]), dtype=np.float32)\n",
        "\n",
        "    def step_wait(self):\n",
        "        obs, reward, done, info = self.venv.step_wait()\n",
        "        return obs.transpose(0,3,1,2), reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        obs = self.venv.reset()\n",
        "        return obs.transpose(0,3,1,2)\n",
        "\n",
        "\n",
        "class ScaledFloatFrame(VecEnvWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(venv=env)\n",
        "        obs_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=obs_shape, dtype=np.float32)\n",
        "\n",
        "    def step_wait(self):\n",
        "        obs, reward, done, info = self.venv.step_wait()\n",
        "        return obs/255.0, reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        obs = self.venv.reset()\n",
        "        return obs/255.0"
      ],
      "metadata": {
        "id": "gjSRnOZyyu5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PPO:\n",
        "    def __init__(self,\n",
        "                 env,\n",
        "                 policy,\n",
        "                 logger,\n",
        "                 storage,\n",
        "                 device,\n",
        "                 n_steps,\n",
        "                 n_envs,\n",
        "                 epoch,\n",
        "                 mini_batch_per_epoch,\n",
        "                 mini_batch_size,\n",
        "                 gamma,\n",
        "                 lmbda,\n",
        "                 learning_rate,\n",
        "                 eps_clip,\n",
        "                 value_coef,\n",
        "                 entropy_coef):\n",
        "\n",
        "        self.env = env\n",
        "        self.policy = policy\n",
        "        self.logger = logger\n",
        "        self.storage = storage\n",
        "        self.device = device\n",
        "        self.n_steps = n_steps\n",
        "        self.n_envs = n_envs\n",
        "        self.epoch = epoch\n",
        "        self.mini_batch_per_epoch = mini_batch_per_epoch\n",
        "        self.mini_batch_size = mini_batch_size\n",
        "        self.gamma = gamma\n",
        "        self.lmbda = lmbda\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimizer = optim.Adam(self.policy.parameters(), lr=learning_rate, eps=1e-5)\n",
        "        self.eps_clip = eps_clip\n",
        "        self.value_coef = value_coef\n",
        "        self.entropy_coef = entropy_coef\n",
        "        self.t = 0\n",
        "\n",
        "    def predict(self, obs, done):\n",
        "        with torch.no_grad():\n",
        "            obs = torch.FloatTensor(obs).to(device=self.device)\n",
        "            dist, value = self.policy(obs)\n",
        "            act = dist.sample()\n",
        "            log_prob_act = dist.log_prob(act)\n",
        "\n",
        "        return act.cpu().numpy(), log_prob_act.cpu().numpy(), value.cpu().numpy()\n",
        "\n",
        "    def optimize(self):\n",
        "        pi_loss_list, value_loss_list, entropy_loss_list = [], [], []\n",
        "        self.policy.train()\n",
        "        for e in range(self.epoch):\n",
        "            generator = self.storage.fetch_train_generator(mini_batch_size=self.mini_batch_size)\n",
        "            for sample in generator:\n",
        "                obs_batch, act_batch, done_batch, \\\n",
        "                    old_log_prob_act_batch, old_value_batch, return_batch, adv_batch = sample\n",
        "                dist_batch, value_batch = self.policy(obs_batch)\n",
        "\n",
        "                # Clipped Surrogate Objective\n",
        "                log_prob_act_batch = dist_batch.log_prob(act_batch)\n",
        "                ratio = torch.exp(log_prob_act_batch - old_log_prob_act_batch)\n",
        "                surr1 = ratio * adv_batch\n",
        "                surr2 = torch.clamp(ratio, 1.0 - self.eps_clip, 1.0 + self.eps_clip) * adv_batch\n",
        "                pi_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "                # useful info to log\n",
        "                approx_kl = (old_log_prob_act_batch - log_prob_act_batch).mean().item()\n",
        "                clipped = ratio.gt(1+self.eps_clip) | ratio.lt(1-self.eps_clip)\n",
        "                clipfrac = torch.as_tensor(clipped, dtype=torch.float32).mean().item()\n",
        "\n",
        "                # Clipped Bellman-Error\n",
        "                clipped_value_batch = old_value_batch + (value_batch - old_value_batch).clamp(-self.eps_clip, self.eps_clip)\n",
        "                v_surr1 = (value_batch - return_batch).pow(2)\n",
        "                v_surr2 = (clipped_value_batch - return_batch).pow(2)\n",
        "                value_loss = 0.5 * torch.max(v_surr1, v_surr2).mean()\n",
        "\n",
        "                # Policy Entropy\n",
        "                entropy_loss = dist_batch.entropy().mean()\n",
        "                loss = pi_loss + self.value_coef * value_loss - self.entropy_coef * entropy_loss\n",
        "                loss.backward()\n",
        "\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "                pi_loss_list.append(pi_loss.item())\n",
        "                value_loss_list.append(value_loss.item())\n",
        "                entropy_loss_list.append(entropy_loss.item())\n",
        "\n",
        "        summary = {'loss/clipfrac': clipfrac,\n",
        "                   'loss/approxkl': approx_kl,\n",
        "                   'loss/policy_loss': np.mean(pi_loss_list),\n",
        "                   'loss/value_loss': np.mean(value_loss_list),\n",
        "                   'loss/policy_entropy': np.mean(entropy_loss_list)}\n",
        "        return summary\n",
        "\n",
        "    def train(self, num_timesteps):\n",
        "        obs = self.env.reset()\n",
        "        done = np.zeros(self.n_envs)\n",
        "\n",
        "        while self.t < num_timesteps:\n",
        "            # Run Policy\n",
        "            self.policy.eval()\n",
        "            for _ in range(self.n_steps):\n",
        "                act, log_prob_act, value = self.predict(obs, done)\n",
        "                next_obs, rew, done, info = self.env.step(act)\n",
        "                self.storage.store(obs, act, rew, done, info, log_prob_act, value)\n",
        "                obs = next_obs\n",
        "            _, _, last_val = self.predict(obs, done)\n",
        "            self.storage.store_last(obs, last_val)\n",
        "            # Compute advantage estimates\n",
        "            self.storage.compute_estimates(self.gamma, self.lmbda)\n",
        "\n",
        "            # Optimize policy & valueq\n",
        "            summary = self.optimize()\n",
        "            # Log the training-procedure\n",
        "            self.t += self.n_steps * self.n_envs\n",
        "            rew_batch, done_batch = self.storage.fetch_log_data()\n",
        "            self.logger.feed(rew_batch, done_batch)\n",
        "            self.logger.write_summary(summary)\n",
        "            self.logger.dump()\n",
        "        self.env.close()"
      ],
      "metadata": {
        "id": "NCM2gL6JzZ30"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 5052531,
          "sourceId": 8473067,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30698,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}