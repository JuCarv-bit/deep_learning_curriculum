{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5: Modeling Objectives\n"
      ],
      "metadata": {
        "id": "ukagYoaIR40z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "YdLtj660QQtC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQJhiJhHK4gy",
        "outputId": "44670d91-83c9-45d9-d8f3-6df9669547ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HIXIdjg5PNud",
        "outputId": "e2c9881d-849b-4434-d49c-f796ff7b4527"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\\nholdout_loader = DataLoader(holdout_set, batch_size=num_holdout_per_class*10, shuffle=False)\\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Hold out a few examples from each class from the training set\n",
        "num_holdout_per_class = 50\n",
        "holdout_indices = []\n",
        "train_indices = []\n",
        "class_counts = {i: 0 for i in range(10)}\n",
        "\n",
        "for idx, (img, label) in enumerate(train_dataset):\n",
        "    if class_counts[label] < num_holdout_per_class:\n",
        "        holdout_indices.append(idx)\n",
        "        class_counts[label] += 1\n",
        "    else:\n",
        "        train_indices.append(idx)\n",
        "\n",
        "holdout_set = Subset(train_dataset, holdout_indices)\n",
        "train_set = Subset(train_dataset, train_indices)\n",
        "\n",
        "\"\"\"\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "holdout_loader = DataLoader(holdout_set, batch_size=num_holdout_per_class*10, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive Loss"
      ],
      "metadata": {
        "id": "kAARnV1dR1YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
        "        loss = torch.mean((1-label) * torch.pow(euclidean_distance, 2) + (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J44brJYDReUK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive CNN Model"
      ],
      "metadata": {
        "id": "I-elSusrSG1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContrastiveCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(1024, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Ohni1afwSAQi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "O_xagrvdSL5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class ContrastiveMNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.labels = [label for _, label in dataset]\n",
        "        self.label_to_indices = {label: np.where(np.array(self.labels) == label)[0] for label in set(self.labels)}\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img1, label1 = self.dataset[index]\n",
        "        if random.randint(0, 1):\n",
        "            # Positive pair\n",
        "            label2 = label1\n",
        "            img2_index = index\n",
        "            while img2_index == index:\n",
        "                img2_index = random.choice(self.label_to_indices[label1])\n",
        "        else:\n",
        "            # Negative pair\n",
        "            label2 = random.choice(list(set(self.labels) - {label1}))\n",
        "            img2_index = random.choice(self.label_to_indices[label2])\n",
        "\n",
        "        img2, _ = self.dataset[img2_index]\n",
        "\n",
        "        label = torch.tensor(int(label1 == label2), dtype=torch.float32)\n",
        "        return img1, img2, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "contrastive_train_dataset = ContrastiveMNISTDataset(train_set)\n",
        "\n",
        "train_loader = DataLoader(contrastive_train_dataset, batch_size=64, shuffle=True)\n",
        "holdout_loader = DataLoader(holdout_set, batch_size=num_holdout_per_class * 10, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "tX9eXmjaTyxm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "model = ContrastiveCNN().to(device)\n",
        "criterion = ContrastiveLoss().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (img1, img2, label) in enumerate(train_loader):\n",
        "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output1 = model(img1)\n",
        "        output2 = model(img2)\n",
        "        loss = criterion(output1, output2, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKTfId5hSLsc",
        "outputId": "a0aa7e18-8b85-4950-e94e-bf520da9ef14"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:56<08:31, 56.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2693414052007019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [01:51<07:24, 55.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.2652581853731986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [02:46<06:27, 55.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.25896600672314246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [03:41<05:30, 55.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.2574675916984517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [04:36<04:36, 55.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 0.25777752104625906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [05:30<03:39, 54.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.25715777335628387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [06:25<02:44, 54.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.25687490927596246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [07:19<01:49, 54.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.257037169991001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [08:13<00:54, 54.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.2571556911032687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [09:07<00:00, 54.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 0.2575170864501307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "o9VQBxPwWbF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "model.eval()\n",
        "holdout_embeddings = []\n",
        "holdout_labels = []\n",
        "\n",
        "#test\n",
        "with torch.no_grad():\n",
        "    for images, labels in holdout_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        embeddings = model(images)\n",
        "        holdout_embeddings.append(embeddings)\n",
        "        holdout_labels.append(labels)\n",
        "\n",
        "holdout_embeddings = torch.cat(holdout_embeddings)\n",
        "holdout_labels = torch.cat(holdout_labels)\n",
        "\n",
        "correct_per_class = [0] * 10\n",
        "total_per_class = [0] * 10\n",
        "correct_total = 0\n",
        "total_total = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        test_embeddings = model(images)\n",
        "        similarities = cosine_similarity(test_embeddings.cpu(), holdout_embeddings.cpu())\n",
        "\n",
        "        # Compute average similarity for each class\n",
        "        avg_similarities = np.zeros((test_embeddings.size(0), 10))\n",
        "        for c in range(10):\n",
        "            class_indices = (holdout_labels == c).nonzero(as_tuple=True)[0]\n",
        "            class_similarities = similarities[:, class_indices.cpu()]\n",
        "            avg_similarities[:, c] = class_similarities.mean(axis=1)\n",
        "\n",
        "\n",
        "        predicted_labels = avg_similarities.argmax(axis=1)\n",
        "\n",
        "        for i, label in enumerate(labels):\n",
        "            if predicted_labels[i] == label:\n",
        "                correct_per_class[label] += 1\n",
        "                correct_total += 1\n",
        "            total_per_class[label] += 1\n",
        "            total_total += 1\n",
        "\n",
        "accuracy_per_class = [correct_per_class[i] / total_per_class[i] if total_per_class[i] > 0 else 0 for i in range(10)]\n",
        "\n",
        "best_class = np.argmax(accuracy_per_class)\n",
        "best_accuracy = accuracy_per_class[best_class]\n",
        "\n",
        "overall_accuracy = correct_total / total_total\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"Class {i} Accuracy: {accuracy_per_class[i] * 100:.2f}%\")\n",
        "\n",
        "print(f\"Best Class: {best_class} with Accuracy: {best_accuracy * 100:.2f}%\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VilvgC-yVdQ7",
        "outputId": "365ddb54-1718-4b34-99aa-7f600eec3c92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 Accuracy: 32.86%\n",
            "Class 1 Accuracy: 14.71%\n",
            "Class 2 Accuracy: 2.71%\n",
            "Class 3 Accuracy: 5.84%\n",
            "Class 4 Accuracy: 9.78%\n",
            "Class 5 Accuracy: 13.34%\n",
            "Class 6 Accuracy: 30.38%\n",
            "Class 7 Accuracy: 8.56%\n",
            "Class 8 Accuracy: 5.85%\n",
            "Class 9 Accuracy: 4.36%\n",
            "Best Class: 0 with Accuracy: 32.86%\n",
            "Overall Accuracy: 12.71%\n"
          ]
        }
      ]
    }
  ]
}